{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f22533a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_pandas in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from sklearn_pandas) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from sklearn_pandas) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from sklearn_pandas) (1.20.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from sklearn_pandas) (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->sklearn_pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->sklearn_pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->sklearn_pandas) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23.0->sklearn_pandas) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23.0->sklearn_pandas) (1.0.1)\n",
      "Requirement already satisfied: torchtuples in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from torchtuples) (1.20.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from torchtuples) (1.2.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from torchtuples) (3.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.3->torchtuples) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->torchtuples) (2021.1)\n",
      "Requirement already satisfied: pycox in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pycox) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pycox) (2.10.0)\n",
      "Requirement already satisfied: torchtuples>=0.2.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pycox) (0.2.2)\n",
      "Requirement already satisfied: feather-format>=0.4.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pycox) (0.4.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pycox) (2.25.1)\n",
      "Requirement already satisfied: numba>=0.44 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pycox) (0.53.1)\n",
      "Requirement already satisfied: py7zr>=0.11.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pycox) (0.20.0)\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from feather-format>=0.4.0->pycox) (9.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from h5py>=2.9.0->pycox) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from h5py>=2.9.0->pycox) (1.20.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from numba>=0.44->pycox) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from numba>=0.44->pycox) (0.36.0)\n",
      "Requirement already satisfied: texttable in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (1.6.4)\n",
      "Requirement already satisfied: pyppmd<0.19.0,>=0.18.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (0.18.3)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (3.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (5.8.0)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (1.0.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (0.3.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from py7zr>=0.11.3->pycox) (0.15.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pycox) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pycox) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pycox) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pycox) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.2->pycox) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.2->pycox) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.2->pycox) (1.0.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from torchtuples>=0.2.0->pycox) (3.3.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from torchtuples>=0.2.0->pycox) (1.2.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2021.1)\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from optuna) (1.4.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from optuna) (4.59.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from optuna) (1.20.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (5.0.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n",
      "Installing collected packages: Mako, importlib-resources, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.0 alembic-1.12.1 colorlog-6.7.0 importlib-resources-6.1.1 optuna-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_pandas\n",
    "!pip install torchtuples\n",
    "!pip install pycox\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665b7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from pycox.models import CoxPH\n",
    "from pycox.models import DeepHitSingle\n",
    "from pycox.evaluation import EvalSurv\n",
    "from pycox.preprocessing.feature_transforms import OrderedCategoricalLong\n",
    "from pycox.datasets import support\n",
    "from pycox.models.loss import rank_loss_deephit_single\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import optuna\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchtuples as tt\n",
    "from pycox.models import CoxPH\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64879588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydata1 = pd.read_csv(\"C:/Users/gyedu/OneDrive/Desktop/SEER Breast Cancer Dataset .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14afd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some of the column\n",
    "mydata1 = mydata1.rename(columns={'Race ': 'Race'})\n",
    "mydata1 = mydata1.rename(columns={'T Stage ': 'TStage'})\n",
    "mydata1= mydata1.rename(columns={'N Stage': 'NStage'})\n",
    "mydata1 = mydata1.rename(columns={'Marital Status': 'Marital'})\n",
    "mydata1= mydata1.rename(columns={'6th Stage': '6thStage'})\n",
    "mydata1 = mydata1.rename(columns={'A Stage': 'AStage'})\n",
    "mydata1 = mydata1.rename(columns={'Estrogen Status': 'EStatus'})\n",
    "mydata1 = mydata1.rename(columns={'Progesterone Status': 'PStatus'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a175ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata1[\"Race\"].replace(\"Other (American Indian/AK Native, Asian/Pacific Islander)\", \"Other\", inplace=True)\n",
    "mydata1[\"Grade\"].replace(\"Well differentiated; Grade I\", \"Grade I\", inplace=True)\n",
    "mydata1[\"Grade\"].replace(\"Moderately differentiated; Grade II\", \"Grade II\", inplace=True)\n",
    "mydata1[\"Grade\"].replace(\"Poorly differentiated; Grade III\", \"Grade III\", inplace=True)\n",
    "mydata1[\"Grade\"].replace(\"Undifferentiated; anaplastic; Grade IV\", \"Grade IV\", inplace=True)\n",
    "mydata1[\"Marital\"].replace(\"Single (never married)\", \"Single\", inplace=True)\n",
    "mydata1[\"Marital\"].replace(\"Married (including common law)\", \"Married\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67efe0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata1['Status'].replace(['Alive','Dead'],[0,1],inplace=True)\n",
    "mydata1['TStage'].replace(['T1','T2','T3','T4'],[0,1,2,3],inplace=True)\n",
    "mydata1['NStage'].replace(['N1','N2','N3'],[0,1,2],inplace=True)\n",
    "mydata1['Grade'].replace(['Grade I','Grade II','Grade III','Grade IV'],[0,1,2,3],inplace=True)\n",
    "mydata1['EStatus'].replace(['Positive','Negative'],[1,0],inplace=True)\n",
    "mydata1['PStatus'].replace(['Positive','Negative'],[1,0],inplace=True)\n",
    "mydata1['AStage'].replace(['Regional','Distant'],[0,1],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800e3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata1 = mydata1.drop('6thStage',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a32f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables into numerical ones using one-hot encoding\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "cat_cols = ['Race','Marital']\n",
    "encoded_cols = encoder.fit_transform(mydata1[cat_cols])\n",
    "encoded_cols_mydata1 = pd.DataFrame(encoded_cols.toarray(), columns=encoder.get_feature_names_out(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97eb42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata1= mydata1.drop(cat_cols, axis=1)\n",
    "mydata1 = pd.concat([mydata1, encoded_cols_mydata1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d4171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata1_test=mydata1.sample(frac=0.2)\n",
    "mydata1_train=mydata1.drop(mydata1_test.index)\n",
    "mydata1_val=mydata1_train.sample(frac=0.2)\n",
    "mydata1_train=mydata1_train.drop(mydata1_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126d54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_stand = ['Age', 'Tumor Size', 'Regional Node Examined', 'Reginol Node Positive', 'TStage', 'NStage', 'Grade']\n",
    "\n",
    "cols_leave = ['EStatus','PStatus','AStage','Race_Black','Race_Other','Race_White', 'Marital_Divorced','Marital_Married','Marital_Separated',\n",
    "              'Marital_Single','Marital_Widowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2223fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize = [([col], StandardScaler()) for col in cols_stand]\n",
    "leave = [(col, None) for col in cols_leave]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc59e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mapper = DataFrameMapper(standardize + leave)\n",
    "x_train = x_mapper.fit_transform(mydata1_train).astype('float32')\n",
    "x_val = x_mapper.transform(mydata1_val).astype('float32')\n",
    "x_test = x_mapper.transform(mydata1_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f5ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target = lambda mydata1: (mydata1['Survival Months'].values, mydata1['Status'].values)\n",
    "y_train = get_target(mydata1_train)\n",
    "y_val = get_target(mydata1_val)\n",
    "durations_test, events_test = get_target(mydata1_test)\n",
    "val = x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9a653a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:20,400] A new study created in memory with name: no-name-f875f9fa-e45d-4413-9112-8c18a232d4a4\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7117\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 6.0744\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.7438\n",
      "3:\t[0s / 1s],\t\ttrain_loss: 4.1384\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 3.9693\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.5371\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 6.3736\n",
      "7:\t[0s / 2s],\t\ttrain_loss: 4.4010\n",
      "8:\t[0s / 2s],\t\ttrain_loss: 10.4458\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 117.7439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:25,508] Trial 0 finished with value: -0.5828051643192488 and parameters: {'lr': 0.07002088557713378, 'num_layers': 6, 'units': 64, 'dropout': 0.28377509609988694, 'batch_size': 70}. Best is trial 0 with value: -0.5828051643192488.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 1s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:27,864] Trial 1 finished with value: -0.43623826291079815 and parameters: {'lr': 4.516364814491408e-05, 'num_layers': 4, 'units': 128, 'dropout': 0.2180483923434674, 'batch_size': 66}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 1s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:30,175] Trial 2 finished with value: -0.5735915492957746 and parameters: {'lr': 0.012004469863160373, 'num_layers': 4, 'units': 128, 'dropout': 0.1715319026814795, 'batch_size': 66}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.0888\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:\t[0s / 0s],\t\ttrain_loss: 3.9027\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8905\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8520\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.8399\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.8324\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:30,978] Trial 3 finished with value: -0.5278169014084507 and parameters: {'lr': 0.0027081953573080287, 'num_layers': 1, 'units': 32, 'dropout': 0.16125598040391015, 'batch_size': 96}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 0s],\t\ttrain_loss: 3.7667\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 3.8193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8299\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7570\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6439\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6734\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6310\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6664\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.6553\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.6197\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.5852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:32,131] Trial 4 finished with value: -0.4538145539906103 and parameters: {'lr': 0.008836105794484869, 'num_layers': 2, 'units': 32, 'dropout': 0.17103870546665992, 'batch_size': 82}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5727\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\ttrain_loss: 3.9548\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.9482\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.9351\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9261\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.8856\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.8878\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:33,267] Trial 5 finished with value: -0.32161580594679184 and parameters: {'lr': 8.077453627303424e-05, 'num_layers': 1, 'units': 32, 'dropout': 0.14827385317310496, 'batch_size': 67}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 0s],\t\ttrain_loss: 3.8569\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7558\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5236\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n",
      "8:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:34,367] Trial 6 finished with value: -0.5748239436619719 and parameters: {'lr': 0.05848096808319752, 'num_layers': 1, 'units': 64, 'dropout': 0.20570976115773928, 'batch_size': 64}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7982\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7137\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6466\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6398\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6107\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5643\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5767\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:35,846] Trial 7 finished with value: -0.4328247261345853 and parameters: {'lr': 0.00020888902493985815, 'num_layers': 2, 'units': 128, 'dropout': 0.29245753530527674, 'batch_size': 68}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5914\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8624\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.8702\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8468\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8256\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7924\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:36,706] Trial 8 finished with value: -0.5342723004694836 and parameters: {'lr': 0.05551626292240577, 'num_layers': 1, 'units': 32, 'dropout': 0.12396606057547431, 'batch_size': 89}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7:\t[0s / 0s],\t\ttrain_loss: 3.7680\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.7802\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 3.7453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.0183\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8830\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.8066\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7914\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7666\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7455\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.7733\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:38,122] Trial 9 finished with value: -0.5408646322378716 and parameters: {'lr': 0.005269877476605227, 'num_layers': 3, 'units': 128, 'dropout': 0.19484560686599514, 'batch_size': 92}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.7177\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.0336\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0287\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.9459\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7696\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 3.7692\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.7554\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.7469\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7169\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:40,294] Trial 10 finished with value: -0.529264475743349 and parameters: {'lr': 0.0006019068307434991, 'num_layers': 6, 'units': 64, 'dropout': 0.2911099841122867, 'batch_size': 76}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 3.7180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 8.2907\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 9.5948\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 6.7285\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.9706\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.9172\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0807\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.6553\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 6.4799\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 9.3504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:42,492] Trial 11 finished with value: -0.5293231611893584 and parameters: {'lr': 0.09784823419023328, 'num_layers': 6, 'units': 64, 'dropout': 0.2442779232078468, 'batch_size': 73}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 4.3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9089\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.9116\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0370\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0737\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0603\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0280\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0154\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0306\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9742\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:44,508] Trial 12 finished with value: -0.3885758998435055 and parameters: {'lr': 0.03184122431237359, 'num_layers': 5, 'units': 64, 'dropout': 0.251381609662297, 'batch_size': 72}. Best is trial 0 with value: -0.5828051643192488.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9665\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.9401\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.8581\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8573\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 3.9208\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.8517\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.8509\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1836\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:46,621] Trial 13 finished with value: -0.3535993740219092 and parameters: {'lr': 0.09933560494210777, 'num_layers': 5, 'units': 64, 'dropout': 0.10264439166700971, 'batch_size': 65}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 3.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7312\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6974\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7078\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7811\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6747\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6756\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.6530\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:48,135] Trial 14 finished with value: -0.42729851330203444 and parameters: {'lr': 0.020495899799311715, 'num_layers': 3, 'units': 64, 'dropout': 0.2547216695457457, 'batch_size': 71}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5981\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7003\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5413\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.4612\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5157\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 3.4579\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.4410\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.4451\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.4496\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.3932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:50,336] Trial 15 finished with value: -0.5509389671361502 and parameters: {'lr': 0.002273783030051699, 'num_layers': 5, 'units': 64, 'dropout': 0.20830184655315437, 'batch_size': 64}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 3.3924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8727\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7973\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7346\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8412\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8142\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7799\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.7591\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.7454\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.7739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:51,508] Trial 16 finished with value: -0.42609546165884193 and parameters: {'lr': 0.03074688594588072, 'num_layers': 2, 'units': 64, 'dropout': 0.2989750319901427, 'batch_size': 79}. Best is trial 0 with value: -0.5828051643192488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:53,363] Trial 17 finished with value: -0.5974569640062598 and parameters: {'lr': 0.01783963482738901, 'num_layers': 4, 'units': 64, 'dropout': 0.2713728248985741, 'batch_size': 71}. Best is trial 17 with value: -0.5974569640062598.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 1s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:55,658] Trial 18 finished with value: -0.47994913928012517 and parameters: {'lr': 0.01569287595235769, 'num_layers': 6, 'units': 64, 'dropout': 0.2703954096428754, 'batch_size': 71}. Best is trial 17 with value: -0.5974569640062598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8134\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7176\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6527\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6481\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5966\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5972\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.6393\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:57,339] Trial 19 finished with value: -0.40661189358372457 and parameters: {'lr': 0.004127055758112998, 'num_layers': 4, 'units': 64, 'dropout': 0.2742288499177198, 'batch_size': 75}. Best is trial 17 with value: -0.5974569640062598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6231\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8667\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6731\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6421\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5582\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5744\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.5656\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5152\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.4988\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.4896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:25:59,477] Trial 20 finished with value: -0.5097711267605634 and parameters: {'lr': 0.0014524609185238469, 'num_layers': 5, 'units': 64, 'dropout': 0.2338626151413977, 'batch_size': 69}. Best is trial 17 with value: -0.5974569640062598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 3.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:01,365] Trial 21 finished with value: -0.6043035993740219 and parameters: {'lr': 0.0410747598368927, 'num_layers': 3, 'units': 64, 'dropout': 0.2276446364431266, 'batch_size': 64}. Best is trial 21 with value: -0.6043035993740219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8049\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7465\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7372\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8523\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8597\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7542\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.7411\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.8161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:02,984] Trial 22 finished with value: -0.43501564945226917 and parameters: {'lr': 0.030901784615647028, 'num_layers': 3, 'units': 64, 'dropout': 0.2723766278567667, 'batch_size': 69}. Best is trial 21 with value: -0.6043035993740219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.8290\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6933\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6474\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5648\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5495\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.4977\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.5254\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5516\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:04,811] Trial 23 finished with value: -0.5784233176838811 and parameters: {'lr': 0.008170266250975937, 'num_layers': 4, 'units': 64, 'dropout': 0.2290719415157113, 'batch_size': 68}. Best is trial 21 with value: -0.6043035993740219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5271\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.4648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7135\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6181\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:06,403] Trial 24 finished with value: -0.5925860719874805 and parameters: {'lr': 0.01539222461808529, 'num_layers': 3, 'units': 64, 'dropout': 0.2605419980366354, 'batch_size': 69}. Best is trial 21 with value: -0.6043035993740219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:08,192] Trial 25 finished with value: -0.5317292644757433 and parameters: {'lr': 0.014964465960127727, 'num_layers': 3, 'units': 64, 'dropout': 0.26385813778395634, 'batch_size': 66}. Best is trial 21 with value: -0.6043035993740219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7623\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6494\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6410\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5424\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6119\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5820\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.6023\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.5480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:09,457] Trial 26 finished with value: -0.5187206572769953 and parameters: {'lr': 0.009722466857163919, 'num_layers': 2, 'units': 64, 'dropout': 0.24155002462777309, 'batch_size': 74}. Best is trial 21 with value: -0.6043035993740219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5767\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.5885\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.4850\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5410\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.4607\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.4479\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.4036\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.4162\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.4616\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.4562\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.4533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:11,195] Trial 27 finished with value: -0.6393388106416276 and parameters: {'lr': 0.005677680841091522, 'num_layers': 3, 'units': 64, 'dropout': 0.25787653225501117, 'batch_size': 64}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 1s],\t\n",
      "4:\t[0s / 1s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:13,758] Trial 28 finished with value: -0.5351134585289515 and parameters: {'lr': 0.005772973418983511, 'num_layers': 4, 'units': 128, 'dropout': 0.22952495456822988, 'batch_size': 64}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8290\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7657\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7876\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8000\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7560\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.8238\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.7256\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:15,286] Trial 29 finished with value: -0.49998043818466353 and parameters: {'lr': 0.04895838814022221, 'num_layers': 3, 'units': 32, 'dropout': 0.2778350487589366, 'batch_size': 67}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.7256\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7520\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6193\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6206\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5620\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5600\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5347\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.5273\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.4853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:16,640] Trial 30 finished with value: -0.5682316118935837 and parameters: {'lr': 0.0030290416256047495, 'num_layers': 2, 'units': 64, 'dropout': 0.28609474610858576, 'batch_size': 70}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5233\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.4810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6743\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6098\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5476\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5488\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5559\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.5632\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5666\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:18,363] Trial 31 finished with value: -0.46555164319248826 and parameters: {'lr': 0.023193129690884183, 'num_layers': 3, 'units': 64, 'dropout': 0.2625955046410515, 'batch_size': 64}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5780\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7157\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6076\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5832\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6742\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6146\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5996\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5510\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5143\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5098\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.4897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:20,021] Trial 32 finished with value: -0.44039514866979657 and parameters: {'lr': 0.01518534208428908, 'num_layers': 3, 'units': 64, 'dropout': 0.25532413258497805, 'batch_size': 67}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7830\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:21,940] Trial 33 finished with value: -0.5696009389671362 and parameters: {'lr': 0.0384685668092618, 'num_layers': 4, 'units': 64, 'dropout': 0.2617947873580853, 'batch_size': 66}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7766\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6314\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6172\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5835\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6618\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.5544\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.6153\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5944\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5015\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 3.5767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:24,077] Trial 34 finished with value: -0.5582942097026604 and parameters: {'lr': 0.006855383160931362, 'num_layers': 4, 'units': 128, 'dropout': 0.24502022501403378, 'batch_size': 70}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:26,032] Trial 35 finished with value: -0.44639084507042254 and parameters: {'lr': 1.0220482023846917e-05, 'num_layers': 4, 'units': 64, 'dropout': 0.28054240147794646, 'batch_size': 66}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6639\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5331\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5036\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.4777\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5104\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.5086\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.4936\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:27,306] Trial 36 finished with value: -0.41827073552425664 and parameters: {'lr': 0.01140808452252845, 'num_layers': 2, 'units': 32, 'dropout': 0.22033946968237317, 'batch_size': 69}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8258\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7599\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7044\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7173\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7025\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7033\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.6938\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7070\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6396\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:28,872] Trial 37 finished with value: -0.5490219092331768 and parameters: {'lr': 0.022241516654177295, 'num_layers': 3, 'units': 64, 'dropout': 0.2393596849683266, 'batch_size': 72}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6949\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5494\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6130\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5946\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5419\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.4935\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.4721\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.4588\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.4601\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:30,605] Trial 38 finished with value: -0.42507824726134585 and parameters: {'lr': 0.009934776137126879, 'num_layers': 3, 'units': 64, 'dropout': 0.25174318125632106, 'batch_size': 65}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4217\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.5323\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3506\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.4282\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.9733\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.9359\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.3271\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0652\n",
      "8:\t[0s / 2s],\t\ttrain_loss: 3.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:33,082] Trial 39 finished with value: -0.6104460093896713 and parameters: {'lr': 0.05153749204713489, 'num_layers': 4, 'units': 128, 'dropout': 0.26625362441629585, 'batch_size': 68}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 3.9162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 7.0788\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.7859\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1818\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.9337\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.5652\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0565\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.9529\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.8927\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:35,294] Trial 40 finished with value: -0.5041862284820031 and parameters: {'lr': 0.0659565739324426, 'num_layers': 4, 'units': 128, 'dropout': 0.2825892390980479, 'batch_size': 67}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 4.6531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.1633\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1259\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2343\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0581\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9823\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.9855\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1214\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.9480\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:37,410] Trial 41 finished with value: -0.3691118935837246 and parameters: {'lr': 0.04286194392501979, 'num_layers': 4, 'units': 128, 'dropout': 0.2669907983992378, 'batch_size': 68}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 3.9587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7400\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6537\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6321\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6166\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6101\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.6857\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.7234\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7258\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6983\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:39,303] Trial 42 finished with value: -0.45710093896713616 and parameters: {'lr': 0.018674558134617554, 'num_layers': 3, 'units': 128, 'dropout': 0.2587783301572108, 'batch_size': 65}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4328\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0046\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.8487\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8628\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8173\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7810\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.8192\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:40,769] Trial 43 finished with value: -0.37316118935837245 and parameters: {'lr': 0.060667558192260836, 'num_layers': 2, 'units': 128, 'dropout': 0.2720042017530677, 'batch_size': 68}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.7319\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6964\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:42,698] Trial 44 finished with value: -0.5562402190923318 and parameters: {'lr': 0.02748901646533359, 'num_layers': 4, 'units': 32, 'dropout': 0.24754049868621011, 'batch_size': 64}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.1104\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1678\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.5352\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.6110\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 6.3120\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.4811\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.9560\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1811\n",
      "8:\t[0s / 2s],\t\ttrain_loss: 6.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:45,165] Trial 45 finished with value: -0.45573161189358374 and parameters: {'lr': 0.04051462796549069, 'num_layers': 5, 'units': 128, 'dropout': 0.29607433173532965, 'batch_size': 71}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\ttrain_loss: 5.1931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:46,774] Trial 46 finished with value: -0.6178599374021909 and parameters: {'lr': 0.08446560952606294, 'num_layers': 3, 'units': 64, 'dropout': 0.29088907044786083, 'batch_size': 66}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 26.3270\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 9.7297\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 5.7278\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 5.4781\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 5.3689\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.9980\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 5.7329\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3330\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.9865\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 5.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:49,058] Trial 47 finished with value: -0.4404342723004695 and parameters: {'lr': 0.08779806851309557, 'num_layers': 4, 'units': 128, 'dropout': 0.29978069181354505, 'batch_size': 65}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:50,573] Trial 48 finished with value: -0.5629107981220657 and parameters: {'lr': 0.06768437146212049, 'num_layers': 3, 'units': 32, 'dropout': 0.28774737975635845, 'batch_size': 66}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9438\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0523\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3663\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.9475\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.0055\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.8662\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1073\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.8494\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.8621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:52,682] Trial 49 finished with value: -0.5847613458528952 and parameters: {'lr': 0.04860627533917521, 'num_layers': 5, 'units': 64, 'dropout': 0.2886899767176994, 'batch_size': 65}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3514\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1802\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1825\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.9727\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9427\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.9525\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.9536\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 4.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:53,886] Trial 50 finished with value: -0.4283059467918623 and parameters: {'lr': 0.09813992943968977, 'num_layers': 2, 'units': 64, 'dropout': 0.2807652006940623, 'batch_size': 77}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 0s],\t\ttrain_loss: 3.9263\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8154\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6115\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6413\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:55,424] Trial 51 finished with value: -0.36414319248826293 and parameters: {'lr': 0.014418034482507582, 'num_layers': 3, 'units': 64, 'dropout': 0.26700667249541826, 'batch_size': 73}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7505\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6563\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7213\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6860\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6647\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5706\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.6113\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.6584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:57,074] Trial 52 finished with value: -0.47380672926447576 and parameters: {'lr': 0.02501633395980531, 'num_layers': 3, 'units': 64, 'dropout': 0.25272071325167106, 'batch_size': 67}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6734\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8341\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7601\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7601\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7233\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7402\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7399\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.7704\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:26:58,676] Trial 53 finished with value: -0.5024647887323944 and parameters: {'lr': 0.03295486673335906, 'num_layers': 3, 'units': 64, 'dropout': 0.2731442637833537, 'batch_size': 69}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:00,719] Trial 54 finished with value: -0.3879792644757433 and parameters: {'lr': 0.05943398285414583, 'num_layers': 4, 'units': 64, 'dropout': 0.25890466789105027, 'batch_size': 64}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7857\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6795\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6972\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7268\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6700\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7136\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.6619\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:02,282] Trial 55 finished with value: -0.3849569640062598 and parameters: {'lr': 0.018371091242229933, 'num_layers': 3, 'units': 64, 'dropout': 0.29202486728239785, 'batch_size': 70}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6171\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7227\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5817\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5890\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5641\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5903\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6210\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5668\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:03,832] Trial 56 finished with value: -0.5846830985915493 and parameters: {'lr': 0.01141426691649013, 'num_layers': 3, 'units': 64, 'dropout': 0.27625512537997016, 'batch_size': 68}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5324\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n",
      "8:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:05,020] Trial 57 finished with value: -0.6111502347417841 and parameters: {'lr': 0.006684351371928103, 'num_layers': 2, 'units': 64, 'dropout': 0.2370981190821119, 'batch_size': 83}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n",
      "0:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n",
      "8:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:06,219] Trial 58 finished with value: -0.6049100156494522 and parameters: {'lr': 0.004618546889589042, 'num_layers': 2, 'units': 64, 'dropout': 0.2363530615466082, 'batch_size': 83}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n",
      "0:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n",
      "8:\t[0s / 0s],\t\n",
      "9:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:07,205] Trial 59 finished with value: -0.5939553990610329 and parameters: {'lr': 0.00510344223439771, 'num_layers': 1, 'units': 128, 'dropout': 0.2314135304918235, 'batch_size': 83}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n",
      "8:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:08,361] Trial 60 finished with value: -0.5093896713615024 and parameters: {'lr': 0.003987330862535429, 'num_layers': 2, 'units': 64, 'dropout': 0.21772067574950965, 'batch_size': 83}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7182\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6982\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6597\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6701\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6224\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.5958\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.6175\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.5866\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 3.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:09,297] Trial 61 finished with value: -0.4871087636932707 and parameters: {'lr': 0.007261822448594195, 'num_layers': 1, 'units': 64, 'dropout': 0.2419515079681212, 'batch_size': 81}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9021\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7606\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6916\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6779\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6501\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6830\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.6520\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.6458\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.6244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:10,491] Trial 62 finished with value: -0.44518779342723 and parameters: {'lr': 0.007288514885341263, 'num_layers': 2, 'units': 64, 'dropout': 0.24836477628535142, 'batch_size': 85}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6167\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8313\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7685\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7671\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7339\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6917\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.7649\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.7339\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.6992\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 3.7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:11,363] Trial 63 finished with value: -0.4803305946791862 and parameters: {'lr': 0.002024791555671958, 'num_layers': 1, 'units': 64, 'dropout': 0.23736861369184115, 'batch_size': 86}. Best is trial 27 with value: -0.6393388106416276.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:12,675] Trial 64 finished with value: -0.5729851330203443 and parameters: {'lr': 0.03343672485306169, 'num_layers': 2, 'units': 64, 'dropout': 0.266500786770009, 'batch_size': 78}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8391\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7408\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6724\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6796\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6607\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5747\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.6158\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:13,966] Trial 65 finished with value: -0.5875978090766824 and parameters: {'lr': 0.0039041218609467323, 'num_layers': 2, 'units': 64, 'dropout': 0.2538806857184339, 'batch_size': 79}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5617\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7115\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.5893\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2624\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0648\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0332\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0348\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0393\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:15,606] Trial 66 finished with value: -0.557433489827856 and parameters: {'lr': 0.07686834569700284, 'num_layers': 4, 'units': 64, 'dropout': 0.23422484581850014, 'batch_size': 80}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0802\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7823\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6986\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6158\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5939\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6338\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5756\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.5900\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.5622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:16,777] Trial 67 finished with value: -0.3908841940532081 and parameters: {'lr': 0.009574598588293804, 'num_layers': 2, 'units': 32, 'dropout': 0.22404619872828835, 'batch_size': 75}. Best is trial 27 with value: -0.6393388106416276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 0s],\t\ttrain_loss: 3.6201\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:18,730] Trial 68 finished with value: -0.668622848200313 and parameters: {'lr': 0.04646340452103316, 'num_layers': 4, 'units': 64, 'dropout': 0.2445880016932464, 'batch_size': 66}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n",
      "8:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:19,906] Trial 69 finished with value: -0.3806338028169014 and parameters: {'lr': 0.04790803235222198, 'num_layers': 1, 'units': 64, 'dropout': 0.2445606913513542, 'batch_size': 66}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7308\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 1s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:22,138] Trial 70 finished with value: -0.5352308294209702 and parameters: {'lr': 0.026046797341203503, 'num_layers': 5, 'units': 64, 'dropout': 0.236603719938207, 'batch_size': 64}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8232\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7227\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.9017\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8143\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9656\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.8308\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.7899\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7652\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.7041\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:24,045] Trial 71 finished with value: -0.5035406885758998 and parameters: {'lr': 0.03644996746343756, 'num_layers': 4, 'units': 64, 'dropout': 0.24961679694776912, 'batch_size': 65}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4695\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.5398\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0841\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1444\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2660\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1730\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.8856\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3234\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9176\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:25,876] Trial 72 finished with value: -0.5021909233176839 and parameters: {'lr': 0.0753696050471555, 'num_layers': 4, 'units': 64, 'dropout': 0.25926461461949185, 'batch_size': 67}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:27,743] Trial 73 finished with value: -0.5443466353677622 and parameters: {'lr': 0.058101925001741425, 'num_layers': 4, 'units': 64, 'dropout': 0.2431876192249831, 'batch_size': 66}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7535\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6293\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5897\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6334\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6229\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5532\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5746\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:29,286] Trial 74 finished with value: -0.38333333333333336 and parameters: {'lr': 0.019917498025044292, 'num_layers': 3, 'units': 64, 'dropout': 0.22883822544708501, 'batch_size': 67}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5544\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7391\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6030\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5687\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5550\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5094\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.4985\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5144\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5110\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5543\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:31,130] Trial 75 finished with value: -0.5025039123630672 and parameters: {'lr': 0.013151197526084093, 'num_layers': 4, 'units': 64, 'dropout': 0.2682698014094169, 'batch_size': 65}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5238\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1010\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.9803\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0167\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9881\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0296\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2001\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2251\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:33,053] Trial 76 finished with value: -0.5605633802816902 and parameters: {'lr': 0.0477412257339571, 'num_layers': 3, 'units': 128, 'dropout': 0.2774173060775189, 'batch_size': 68}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.9040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7375\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5546\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5540\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5434\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6343\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6197\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.6118\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:34,475] Trial 77 finished with value: -0.5099178403755869 and parameters: {'lr': 0.03010293183393384, 'num_layers': 2, 'units': 64, 'dropout': 0.28357372072052767, 'batch_size': 64}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6926\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.0760\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.9797\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.8732\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8192\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8138\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.8346\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.8207\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.8188\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.7124\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:36,228] Trial 78 finished with value: -0.5260954616588419 and parameters: {'lr': 0.005439782769274205, 'num_layers': 5, 'units': 64, 'dropout': 0.2550527156304514, 'batch_size': 89}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 1s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:38,614] Trial 79 finished with value: -0.5728873239436619 and parameters: {'lr': 0.02104935134849157, 'num_layers': 4, 'units': 128, 'dropout': 0.20994302097199008, 'batch_size': 66}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 2s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9267\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8592\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.8317\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.9020\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8830\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.8064\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.9340\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:39,940] Trial 80 finished with value: -0.5839593114241002 and parameters: {'lr': 0.04003329300660388, 'num_layers': 3, 'units': 32, 'dropout': 0.23736334680071425, 'batch_size': 81}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.8621\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8084\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n",
      "8:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:40,937] Trial 81 finished with value: -0.5588419405320814 and parameters: {'lr': 0.00590106055562657, 'num_layers': 1, 'units': 128, 'dropout': 0.2312640272275715, 'batch_size': 83}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 0s],\t\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7212\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7189\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6961\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6188\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6882\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.6225\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.6050\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.6202\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 3.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:41,912] Trial 82 finished with value: -0.5138693270735524 and parameters: {'lr': 0.004599727338836495, 'num_layers': 1, 'units': 128, 'dropout': 0.24697320232835807, 'batch_size': 84}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9815\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7886\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7295\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7330\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7200\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7189\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.7138\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.6753\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 3.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:42,863] Trial 83 finished with value: -0.35418622848200315 and parameters: {'lr': 0.0028716296272735817, 'num_layers': 1, 'units': 128, 'dropout': 0.22689051317903097, 'batch_size': 86}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 0s],\t\ttrain_loss: 3.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9071\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8006\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7285\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7258\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7072\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.7680\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.7029\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.6827\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6510\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:44,764] Trial 84 finished with value: -0.49839593114241004 and parameters: {'lr': 0.008335393566096637, 'num_layers': 4, 'units': 128, 'dropout': 0.23360817274215273, 'batch_size': 82}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6932\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5887\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.4726\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5161\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5475\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 3.4686\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.4942\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5169\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:46,670] Trial 85 finished with value: -0.4387519561815336 and parameters: {'lr': 0.011675045782819624, 'num_layers': 3, 'units': 128, 'dropout': 0.22232245295804764, 'batch_size': 65}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 1s],\t\ttrain_loss: 3.4957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7906\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6194\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5772\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5754\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5771\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5186\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.5195\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.5099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:47,726] Trial 86 finished with value: -0.4409037558685446 and parameters: {'lr': 0.003353256092129476, 'num_layers': 1, 'units': 64, 'dropout': 0.24180394272018815, 'batch_size': 72}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 0s],\t\ttrain_loss: 3.5381\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 3.4971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9135\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8550\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1291\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8563\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9461\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0511\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.8928\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 3.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:49,058] Trial 87 finished with value: -0.41161971830985916 and parameters: {'lr': 0.08122000305815608, 'num_layers': 2, 'units': 64, 'dropout': 0.26181286180434166, 'batch_size': 67}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9404\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.5966\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.4989\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 1s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:51,055] Trial 88 finished with value: -0.5625586854460094 and parameters: {'lr': 0.005115069824092372, 'num_layers': 3, 'units': 128, 'dropout': 0.2707970206650314, 'batch_size': 64}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:52,466] Trial 89 finished with value: -0.523141627543036 and parameters: {'lr': 0.017411358501414818, 'num_layers': 4, 'units': 64, 'dropout': 0.21616870704313867, 'batch_size': 99}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8460\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8033\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7049\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6764\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.7698\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.8487\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.8256\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7957\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.8233\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:54,261] Trial 90 finished with value: -0.38190532081377154 and parameters: {'lr': 0.02485857216537861, 'num_layers': 4, 'units': 64, 'dropout': 0.25723071921605895, 'batch_size': 70}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7493\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.6430\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6102\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5940\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5634\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5828\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5402\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5786\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5686\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:55,835] Trial 91 finished with value: -0.5408450704225352 and parameters: {'lr': 0.014950906351150128, 'num_layers': 3, 'units': 64, 'dropout': 0.25100826319191843, 'batch_size': 69}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6798\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5580\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5656\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5331\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.5640\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.5207\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.5361\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5282\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.5111\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.5049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:57,461] Trial 92 finished with value: -0.5097026604068857 and parameters: {'lr': 0.009295817799955556, 'num_layers': 3, 'units': 64, 'dropout': 0.2650776653141163, 'batch_size': 68}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\n",
      "1:\t[0s / 0s],\t\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 1s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:27:59,128] Trial 93 finished with value: -0.5623826291079812 and parameters: {'lr': 0.006507952845564035, 'num_layers': 3, 'units': 64, 'dropout': 0.23985631787681444, 'batch_size': 66}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8647\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.8960\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.9090\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.8789\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9087\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.8957\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.8601\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0185\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.8704\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:28:00,884] Trial 94 finished with value: -0.514397496087637 and parameters: {'lr': 0.06385914088894831, 'num_layers': 3, 'units': 64, 'dropout': 0.25680901603960776, 'batch_size': 65}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.6405\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.5552\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.5227\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.5832\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 0s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:28:02,223] Trial 95 finished with value: -0.46081768388106414 and parameters: {'lr': 0.013050006050949466, 'num_layers': 2, 'units': 64, 'dropout': 0.24845400650381672, 'batch_size': 69}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.9024\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7704\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7300\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.6471\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6938\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7209\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 3.6943\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.5876\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6163\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:28:03,938] Trial 96 finished with value: -0.4513302034428795 and parameters: {'lr': 0.007644944867415589, 'num_layers': 4, 'units': 64, 'dropout': 0.2758415567833144, 'batch_size': 77}. Best is trial 68 with value: -0.668622848200313.\n",
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8427\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7611\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.6668\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7017\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.6755\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.6682\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.6778\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:28:05,356] Trial 97 finished with value: -0.6091158059467918 and parameters: {'lr': 0.016687484124560465, 'num_layers': 3, 'units': 32, 'dropout': 0.2626942344342772, 'batch_size': 73}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.6569\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.7928\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7211\n",
      "2:\t[0s / 0s],\t\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:28:06,816] Trial 98 finished with value: -0.5824139280125196 and parameters: {'lr': 0.031061437715974725, 'num_layers': 3, 'units': 32, 'dropout': 0.26377924509828504, 'batch_size': 71}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2a438a89e78f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.8316\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.7438\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.7546\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 3.7481\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.8154\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.7893\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.7817\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 00:28:08,140] Trial 99 finished with value: -0.5963419405320813 and parameters: {'lr': 0.05270462122349618, 'num_layers': 2, 'units': 32, 'dropout': 0.27223359690518756, 'batch_size': 73}. Best is trial 68 with value: -0.668622848200313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 1s],\t\ttrain_loss: 3.7721\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.6913\n",
      "Best parameters:  {'lr': 0.04646340452103316, 'num_layers': 4, 'units': 64, 'dropout': 0.2445880016932464, 'batch_size': 66}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def create_net(trial, input_features):\n",
    "    # Define hyperparameters\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 6)\n",
    "    units = trial.suggest_categorical('units', [32,64, 128])\n",
    "    dropout = trial.suggest_float('dropout',  0.1, 0.3)\n",
    "    #lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "\n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            layers.append(torch.nn.Linear(input_features, units))\n",
    "        else:\n",
    "            layers.append(torch.nn.Linear(units, units))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Dropout(dropout))\n",
    "\n",
    "    layers.append(torch.nn.Linear(units, 1))  # Output layer\n",
    "    return torch.nn.Sequential(*layers)\n",
    "\n",
    "# Then, use this function in your objective:\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    net = create_net(trial, input_features=x_train.shape[1])\n",
    "    model = CoxPH(net, optimizer=tt.optim.Adam(lr=lr))\n",
    "\n",
    "    # Fit model\n",
    "    batch_size = trial.suggest_int('batch_size', 64, 100, log=True)\n",
    "    model.fit(x_train, y_train, batch_size, epochs=100, callbacks=[tt.callbacks.EarlyStopping()])\n",
    "\n",
    "    # Evaluate model\n",
    "    _ = model.compute_baseline_hazards()\n",
    "    # surv = model.predict_surv_df(x_test)\n",
    "    surv = model.predict_surv_df(x_val)\n",
    "    ev = EvalSurv(surv, y_val[0], y_val[1], censor_surv='km')\n",
    "    c_index = ev.concordance_td()\n",
    "\n",
    "    return -c_index  # Negative C-index because Optuna minimizes the objective\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54c9b94e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5772,\tval_loss: 3.8353\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2672,\tval_loss: 3.8408\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1373,\tval_loss: 3.8617\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1055,\tval_loss: 3.6201\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1408,\tval_loss: 3.7076\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1553,\tval_loss: 3.6751\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1428,\tval_loss: 3.7401\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1222,\tval_loss: 3.6792\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0743,\tval_loss: 3.5233\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1605,\tval_loss: 3.6955\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1090,\tval_loss: 3.7235\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.5375,\tval_loss: 3.8166\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2052,\tval_loss: 3.8794\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1127,\tval_loss: 3.8820\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2053,\tval_loss: 3.8975\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.3906,\tval_loss: 3.8915\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2287,\tval_loss: 3.8918\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.3247,\tval_loss: 3.8918\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1985,\tval_loss: 3.8918\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3471,\tval_loss: 3.6637\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1580,\tval_loss: 3.6020\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1526,\tval_loss: 3.6118\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2272,\tval_loss: 3.7692\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1651,\tval_loss: 3.6686\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2280,\tval_loss: 3.8264\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1373,\tval_loss: 3.6493\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 4.2703,\tval_loss: 3.7549\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1519,\tval_loss: 3.7648\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1692,\tval_loss: 3.8520\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2338,\tval_loss: 3.7970\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1735,\tval_loss: 3.5794\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2000,\tval_loss: 3.8657\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1848,\tval_loss: 3.8657\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1926,\tval_loss: 3.8657\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2157,\tval_loss: 3.8657\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1941,\tval_loss: 3.8659\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1943,\tval_loss: 3.8657\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2295,\tval_loss: 3.8657\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2115,\tval_loss: 3.8657\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.2138,\tval_loss: 3.8657\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2686,\tval_loss: 3.8657\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3529,\tval_loss: 3.5977\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1259,\tval_loss: 3.5066\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1292,\tval_loss: 3.6139\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1062,\tval_loss: 3.6047\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0416,\tval_loss: 3.6160\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0614,\tval_loss: 3.4896\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1503,\tval_loss: 3.7522\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1881,\tval_loss: 3.6995\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2699,\tval_loss: 3.7307\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2723,\tval_loss: 3.8194\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2220,\tval_loss: 3.6736\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.6702,\tval_loss: 3.8246\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2482,\tval_loss: 3.8250\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1976,\tval_loss: 3.8250\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2049,\tval_loss: 3.8250\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2548,\tval_loss: 3.8250\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3103,\tval_loss: 3.7316\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0946,\tval_loss: 3.7498\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1165,\tval_loss: 3.8592\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1132,\tval_loss: 3.9658\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.4027,\tval_loss: 3.8492\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0799,\tval_loss: 3.8817\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0804,\tval_loss: 3.8002\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0632,\tval_loss: 3.7982\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9852,\tval_loss: 3.8009\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0650,\tval_loss: 3.8713\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0625,\tval_loss: 3.9079\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4730,\tval_loss: 3.7241\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2207,\tval_loss: 3.8008\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1657,\tval_loss: 3.8258\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2157,\tval_loss: 3.7066\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1417,\tval_loss: 3.8357\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2037,\tval_loss: 3.7459\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1262,\tval_loss: 3.7707\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1087,\tval_loss: 3.6929\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1465,\tval_loss: 3.7762\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.6436,\tval_loss: 3.8432\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1941,\tval_loss: 3.7182\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1113,\tval_loss: 3.9331\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1597,\tval_loss: 3.8796\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1371,\tval_loss: 3.8796\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1482,\tval_loss: 3.8423\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2470,\tval_loss: 3.8795\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2096,\tval_loss: 3.8755\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2619,\tval_loss: 3.8796\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.8759,\tval_loss: 3.8079\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1277,\tval_loss: 3.7275\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1606,\tval_loss: 3.8537\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0368,\tval_loss: 3.7821\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1578,\tval_loss: 3.7898\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1430,\tval_loss: 3.8383\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0726,\tval_loss: 3.8670\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1198,\tval_loss: 3.7075\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9878,\tval_loss: 3.8949\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0939,\tval_loss: 3.7354\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0056,\tval_loss: 3.8090\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0765,\tval_loss: 3.6381\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0059,\tval_loss: 3.7059\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0179,\tval_loss: 3.6862\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0334,\tval_loss: 3.7317\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1418,\tval_loss: 3.8048\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1433,\tval_loss: 3.7635\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1292,\tval_loss: 3.7538\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2413,\tval_loss: 3.6951\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0941,\tval_loss: 3.8519\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.3116,\tval_loss: 3.7302\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.0834,\tval_loss: 3.7905\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6381,\tval_loss: 3.9547\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2524,\tval_loss: 3.9139\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1783,\tval_loss: 3.8076\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1337,\tval_loss: 3.7109\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2470,\tval_loss: 3.9219\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1778,\tval_loss: 3.9195\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1047,\tval_loss: 3.8543\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2479,\tval_loss: 3.8984\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1902,\tval_loss: 3.7639\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2236,\tval_loss: 3.9447\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1902,\tval_loss: 3.8706\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1713,\tval_loss: 3.8511\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.5848,\tval_loss: 3.8692\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1885,\tval_loss: 3.8914\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4754,\tval_loss: 3.7514\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1190,\tval_loss: 3.7446\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1442,\tval_loss: 3.7264\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1488,\tval_loss: 3.6601\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0938,\tval_loss: 3.8307\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1955,\tval_loss: 3.8097\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1329,\tval_loss: 3.7108\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1722,\tval_loss: 3.7925\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2454,\tval_loss: 4.0238\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2631,\tval_loss: 3.7456\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2536,\tval_loss: 3.7665\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2300,\tval_loss: 3.8665\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2250,\tval_loss: 4.2965\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2499,\tval_loss: 3.8449\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4418,\tval_loss: 3.7674\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1768,\tval_loss: 3.7988\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1956,\tval_loss: 3.5764\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1236,\tval_loss: 3.8956\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2028,\tval_loss: 3.8485\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1053,\tval_loss: 3.7574\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1581,\tval_loss: 3.8328\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0957,\tval_loss: 3.7340\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0513,\tval_loss: 3.7694\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1719,\tval_loss: 3.7838\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1231,\tval_loss: 3.7572\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1807,\tval_loss: 4.3893\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.4797,\tval_loss: 3.9218\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3702,\tval_loss: 4.0406\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2408,\tval_loss: 3.8619\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1440,\tval_loss: 3.9489\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1458,\tval_loss: 3.7694\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1343,\tval_loss: 3.9067\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1538,\tval_loss: 3.8185\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1064,\tval_loss: 3.6603\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1389,\tval_loss: 3.9245\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2585,\tval_loss: 3.8935\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2692,\tval_loss: 3.9448\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1891,\tval_loss: 3.9216\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1813,\tval_loss: 3.8109\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2434,\tval_loss: 4.0037\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.3846,\tval_loss: 4.0776\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2347,\tval_loss: 3.9160\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2511,\tval_loss: 3.9503\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.3439,\tval_loss: 3.9600\n",
      "Iteration 1, Average C-index: 0.7192274003503636, Average IBS: 0.09250202113503819\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.2980,\tval_loss: 3.6950\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0841,\tval_loss: 3.4603\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1610,\tval_loss: 3.5380\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1662,\tval_loss: 3.8631\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2188,\tval_loss: 3.6921\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1972,\tval_loss: 3.6189\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2024,\tval_loss: 3.7769\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2346,\tval_loss: 3.7525\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.3538,\tval_loss: 3.6792\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1357,\tval_loss: 3.8111\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1802,\tval_loss: 3.7065\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1593,\tval_loss: 3.6510\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3915,\tval_loss: 3.5799\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0945,\tval_loss: 3.7190\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2032,\tval_loss: 3.7016\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1610,\tval_loss: 3.6334\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1567,\tval_loss: 3.5538\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1112,\tval_loss: 3.6679\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1310,\tval_loss: 4.1597\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2083,\tval_loss: 3.7177\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2469,\tval_loss: 3.7563\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1904,\tval_loss: 3.7363\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.9330,\tval_loss: 3.7566\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2114,\tval_loss: 3.7566\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.4433,\tval_loss: 3.7566\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1947,\tval_loss: 3.7566\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2106,\tval_loss: 3.7566\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3934,\tval_loss: 3.8997\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1605,\tval_loss: 3.5333\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1030,\tval_loss: 3.5244\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0713,\tval_loss: 3.4194\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1316,\tval_loss: 3.6601\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1408,\tval_loss: 3.5318\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1347,\tval_loss: 3.6618\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2258,\tval_loss: 3.6502\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1617,\tval_loss: 3.6586\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1828,\tval_loss: 3.7076\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1131,\tval_loss: 3.4608\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0493,\tval_loss: 3.3632\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0365,\tval_loss: 3.5171\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0977,\tval_loss: 3.5439\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0655,\tval_loss: 3.6532\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0535,\tval_loss: 3.7180\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0738,\tval_loss: 3.2891\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0771,\tval_loss: 3.6173\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0671,\tval_loss: 3.3516\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0764,\tval_loss: 3.4923\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.0601,\tval_loss: 3.4705\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1371,\tval_loss: 3.5511\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.4911,\tval_loss: 3.8047\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1916,\tval_loss: 3.7808\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1799,\tval_loss: 3.6834\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1797,\tval_loss: 3.8113\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.1703,\tval_loss: 3.8135\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5312,\tval_loss: 3.6725\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1590,\tval_loss: 3.7536\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0435,\tval_loss: 3.6564\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1524,\tval_loss: 3.7941\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2020,\tval_loss: 3.7444\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1767,\tval_loss: 3.7812\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1726,\tval_loss: 3.7276\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1688,\tval_loss: 3.7677\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1606,\tval_loss: 3.8012\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1838,\tval_loss: 3.7555\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2019,\tval_loss: 4.2180\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3036,\tval_loss: 3.8112\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1618,\tval_loss: 3.8218\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4231,\tval_loss: 3.7161\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1923,\tval_loss: 3.2987\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1116,\tval_loss: 3.5109\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2154,\tval_loss: 3.6123\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1560,\tval_loss: 3.5048\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1427,\tval_loss: 3.5139\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1452,\tval_loss: 3.6890\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1636,\tval_loss: 3.7523\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1914,\tval_loss: 3.6932\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3594,\tval_loss: 3.8024\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2403,\tval_loss: 3.7996\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2532,\tval_loss: 3.8272\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3605,\tval_loss: 3.6854\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1920,\tval_loss: 3.4791\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1882,\tval_loss: 3.6554\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1826,\tval_loss: 3.5430\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1605,\tval_loss: 3.6253\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1505,\tval_loss: 3.5324\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1575,\tval_loss: 3.6478\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2377,\tval_loss: 3.6362\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2245,\tval_loss: 3.6853\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2996,\tval_loss: 3.6383\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1763,\tval_loss: 3.5344\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1721,\tval_loss: 3.6823\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.3741,\tval_loss: 3.7524\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1705,\tval_loss: 3.8575\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2066,\tval_loss: 3.8795\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1960,\tval_loss: 3.8342\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1051,\tval_loss: 3.8148\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0907,\tval_loss: 4.0124\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0761,\tval_loss: 3.8464\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0982,\tval_loss: 3.8858\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0976,\tval_loss: 3.8486\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0081,\tval_loss: 3.8786\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1464,\tval_loss: 3.9292\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5196,\tval_loss: 3.7144\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1692,\tval_loss: 3.7478\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0789,\tval_loss: 3.6579\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0795,\tval_loss: 3.7478\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1406,\tval_loss: 3.7868\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1045,\tval_loss: 3.6045\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2412,\tval_loss: 3.6861\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2188,\tval_loss: 3.6952\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1779,\tval_loss: 3.5153\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3772,\tval_loss: 3.7066\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3218,\tval_loss: 3.6348\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2439,\tval_loss: 3.5517\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0709,\tval_loss: 3.4989\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1147,\tval_loss: 3.5283\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1145,\tval_loss: 3.7324\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1215,\tval_loss: 3.5199\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0984,\tval_loss: 3.7405\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0573,\tval_loss: 3.6457\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1579,\tval_loss: 3.7605\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1822,\tval_loss: 3.6752\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1648,\tval_loss: 3.7479\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1474,\tval_loss: 3.7207\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1737,\tval_loss: 3.6633\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4095\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1816\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1958\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0564\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0521\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0621\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0936\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0999\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1215\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1780\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4502,\tval_loss: 3.6229\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1285,\tval_loss: 3.5930\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1508,\tval_loss: 3.7122\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1733,\tval_loss: 3.6735\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1748,\tval_loss: 3.7888\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1508,\tval_loss: 3.6022\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1332,\tval_loss: 3.7684\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0900,\tval_loss: 3.5588\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1109,\tval_loss: 3.7562\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1263,\tval_loss: 3.7069\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1473,\tval_loss: 3.7373\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3371,\tval_loss: 3.7920\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.3034,\tval_loss: 3.7190\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1580,\tval_loss: 3.7834\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1155,\tval_loss: 3.8428\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2333,\tval_loss: 3.6702\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1314,\tval_loss: 3.7433\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1204,\tval_loss: 3.7847\n",
      "Iteration 2, Average C-index: 0.6931823090398599, Average IBS: 0.09167397355766467\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4235,\tval_loss: 3.7146\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1192,\tval_loss: 3.5715\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1508,\tval_loss: 3.8004\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1855,\tval_loss: 3.8048\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2211,\tval_loss: 3.7962\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2236,\tval_loss: 3.8229\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2429,\tval_loss: 3.8231\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1766,\tval_loss: 3.6818\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1962,\tval_loss: 3.6525\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1552,\tval_loss: 3.6528\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2293,\tval_loss: 3.7670\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3640,\tval_loss: 3.8856\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6241,\tval_loss: 3.7379\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1115,\tval_loss: 3.7140\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1286,\tval_loss: 3.6141\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2114,\tval_loss: 3.6851\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1576,\tval_loss: 3.6855\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2143,\tval_loss: 3.7976\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.4626,\tval_loss: 3.6670\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2270,\tval_loss: 3.7619\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1303,\tval_loss: 3.7167\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3952,\tval_loss: 3.7528\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1468,\tval_loss: 3.6899\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1865,\tval_loss: 3.6672\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2276,\tval_loss: 3.7596\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3077,\tval_loss: 3.9699\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2076,\tval_loss: 3.7874\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1995,\tval_loss: 3.7286\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1602,\tval_loss: 3.8210\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1448,\tval_loss: 3.7841\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1415,\tval_loss: 3.8831\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1499,\tval_loss: 4.1483\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0726,\tval_loss: 4.1008\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2266,\tval_loss: 3.8371\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2787,\tval_loss: 3.8169\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2771,\tval_loss: 3.7060\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1394,\tval_loss: 5.9799\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1228,\tval_loss: 4.1241\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1911,\tval_loss: 3.9320\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2806,\tval_loss: 3.9972\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.3133,\tval_loss: 3.7567\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.9088,\tval_loss: 3.9538\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.5502,\tval_loss: 3.7655\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2291,\tval_loss: 3.7655\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2034,\tval_loss: 3.7655\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.2042,\tval_loss: 3.8621\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4394,\tval_loss: 4.0208\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0721,\tval_loss: 4.0718\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0428,\tval_loss: 3.9472\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1415,\tval_loss: 4.0699\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2165,\tval_loss: 4.2010\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2605,\tval_loss: 3.9474\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1864,\tval_loss: 4.0560\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2648,\tval_loss: 4.0455\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2251,\tval_loss: 4.0733\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2695,\tval_loss: 4.0726\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2008,\tval_loss: 4.0726\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1146,\tval_loss: 4.0165\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2101,\tval_loss: 3.9466\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1127,\tval_loss: 3.9368\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2146,\tval_loss: 4.0442\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.7724,\tval_loss: 4.0726\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2804,\tval_loss: 4.0726\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1889,\tval_loss: 4.0726\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1843,\tval_loss: 4.0726\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2186,\tval_loss: 4.0726\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1936,\tval_loss: 4.0726\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1945,\tval_loss: 4.0726\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1784,\tval_loss: 4.0726\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1798,\tval_loss: 4.0726\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4680,\tval_loss: 3.7497\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2951,\tval_loss: 3.7968\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1428,\tval_loss: 3.7460\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0062,\tval_loss: 3.5632\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1375,\tval_loss: 3.6572\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0036,\tval_loss: 3.6334\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1338,\tval_loss: 3.7401\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1513,\tval_loss: 3.6951\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0404,\tval_loss: 3.3837\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0655,\tval_loss: 3.6868\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0209,\tval_loss: 3.6006\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 3.9937,\tval_loss: 3.5360\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.0494,\tval_loss: 3.5950\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0263,\tval_loss: 3.7116\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0719,\tval_loss: 3.7674\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0970,\tval_loss: 3.7572\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.3294,\tval_loss: 3.7414\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0084,\tval_loss: 3.7823\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1660,\tval_loss: 3.8190\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4161,\tval_loss: 3.7629\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0837,\tval_loss: 3.4735\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1617,\tval_loss: 3.5411\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1116,\tval_loss: 3.5564\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1768,\tval_loss: 3.8098\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1774,\tval_loss: 3.9104\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2298,\tval_loss: 3.7953\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1362,\tval_loss: 3.6311\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.4189,\tval_loss: 3.7820\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1040,\tval_loss: 3.7007\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1459,\tval_loss: 3.6728\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1015,\tval_loss: 3.6400\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6288,\tval_loss: 3.7467\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1980,\tval_loss: 3.6440\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0541,\tval_loss: 3.5837\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0330,\tval_loss: 3.5246\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1104,\tval_loss: 3.5888\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1602,\tval_loss: 3.6313\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1455,\tval_loss: 3.7250\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1735,\tval_loss: 3.6001\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0797,\tval_loss: 3.8031\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1185,\tval_loss: 3.8376\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1737,\tval_loss: 3.7438\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3455,\tval_loss: 3.7368\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.3593,\tval_loss: 3.7554\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.6514,\tval_loss: 3.7986\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6263,\tval_loss: 3.6267\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1139,\tval_loss: 3.5821\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1671,\tval_loss: 3.6048\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1440,\tval_loss: 3.5720\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1741,\tval_loss: 3.5954\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1246,\tval_loss: 3.5227\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1127,\tval_loss: 3.5721\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1934,\tval_loss: 3.6676\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2355,\tval_loss: 3.6613\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1804,\tval_loss: 3.6275\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1011,\tval_loss: 3.5405\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 5.0675,\tval_loss: 3.6700\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2705,\tval_loss: 3.6713\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1973,\tval_loss: 3.6713\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2129,\tval_loss: 3.6713\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2179,\tval_loss: 3.6713\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5398,\tval_loss: 3.7460\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1133,\tval_loss: 3.8054\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2157,\tval_loss: 3.6670\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1801,\tval_loss: 3.8189\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0975,\tval_loss: 3.7647\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0245,\tval_loss: 3.7795\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0480,\tval_loss: 3.7876\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.9910,\tval_loss: 3.6052\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9775,\tval_loss: 3.6980\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0047,\tval_loss: 3.7017\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1232,\tval_loss: 3.8135\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0803,\tval_loss: 3.7741\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1918,\tval_loss: 3.6204\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1303,\tval_loss: 3.7747\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1633,\tval_loss: 3.7173\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1367,\tval_loss: 3.6416\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0134,\tval_loss: 3.5130\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0461,\tval_loss: 3.7337\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0861,\tval_loss: 3.7357\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0824,\tval_loss: 3.7073\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.0620,\tval_loss: 3.6763\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.5571,\tval_loss: 3.6306\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.0993,\tval_loss: 3.7773\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1014,\tval_loss: 3.7665\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1802,\tval_loss: 3.8342\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1166,\tval_loss: 3.7913\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.1796,\tval_loss: 4.0680\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7021,\tval_loss: 3.1609\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2001,\tval_loss: 3.5030\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1319,\tval_loss: 3.1359\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2264,\tval_loss: 3.4821\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.3406,\tval_loss: 3.5706\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1716,\tval_loss: 3.5292\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2152,\tval_loss: 3.4971\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1482,\tval_loss: 3.3530\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1049,\tval_loss: 3.5043\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1590,\tval_loss: 3.4865\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1076,\tval_loss: 3.4572\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1217,\tval_loss: 3.2858\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0551,\tval_loss: 3.5941\n",
      "Iteration 3, Average C-index: 0.7025041395694849, Average IBS: 0.09319991712030071\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4488,\tval_loss: 3.7011\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1688,\tval_loss: 3.7092\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1707,\tval_loss: 3.7754\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1254,\tval_loss: 3.7767\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0784,\tval_loss: 3.8120\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0331,\tval_loss: 3.6821\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0755,\tval_loss: 3.7366\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1436,\tval_loss: 3.7633\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0666,\tval_loss: 3.6810\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0857,\tval_loss: 3.7695\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0398,\tval_loss: 3.6522\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0290,\tval_loss: 3.7854\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.6144,\tval_loss: 3.7906\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2280,\tval_loss: 3.9052\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.4539,\tval_loss: 3.9210\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.3218,\tval_loss: 3.8461\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2799,\tval_loss: 3.9220\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2441,\tval_loss: 3.9220\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2550,\tval_loss: 3.9220\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2440,\tval_loss: 3.9220\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.2286,\tval_loss: 3.9220\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3304,\tval_loss: 3.8136\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1149,\tval_loss: 3.8509\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2276,\tval_loss: 3.7600\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1708,\tval_loss: 3.8151\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1650,\tval_loss: 3.6925\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1332,\tval_loss: 3.8176\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2299,\tval_loss: 3.7488\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1563,\tval_loss: 3.7379\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1251,\tval_loss: 3.7664\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1860,\tval_loss: 3.6556\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0618,\tval_loss: 3.6867\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0245,\tval_loss: 3.6715\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0537,\tval_loss: 3.7771\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1051,\tval_loss: 3.6270\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0592,\tval_loss: 3.6484\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0908,\tval_loss: 3.7218\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0957,\tval_loss: 3.8338\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2132,\tval_loss: 3.7255\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0394,\tval_loss: 3.7114\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0486,\tval_loss: 3.6864\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 5.0121,\tval_loss: 3.7307\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.0308,\tval_loss: 3.6479\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.0391,\tval_loss: 3.6798\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.0419,\tval_loss: 3.7221\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5596\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1444\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1899\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0969\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1806\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0763\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1299\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1344\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0645\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1332\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3683,\tval_loss: 3.7504\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1501,\tval_loss: 3.6961\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1198,\tval_loss: 3.6711\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2820,\tval_loss: 3.7275\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1875,\tval_loss: 3.7624\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2802,\tval_loss: 3.7118\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.3843,\tval_loss: 3.6897\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2041,\tval_loss: 3.8367\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.4525,\tval_loss: 3.7450\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.5499,\tval_loss: 3.7495\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2344,\tval_loss: 3.7580\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2997,\tval_loss: 3.7600\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2325,\tval_loss: 3.7580\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4651,\tval_loss: 3.8693\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1522,\tval_loss: 3.7777\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1391,\tval_loss: 3.7408\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1952,\tval_loss: 3.7526\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1051,\tval_loss: 3.7702\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1343,\tval_loss: 3.7022\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0689,\tval_loss: 3.6670\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1175,\tval_loss: 3.5766\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2000,\tval_loss: 3.7690\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2810,\tval_loss: 3.7768\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1535,\tval_loss: 3.7919\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1907,\tval_loss: 3.7502\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1875,\tval_loss: 3.7688\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2350,\tval_loss: 3.7651\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1528,\tval_loss: 3.6822\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1029,\tval_loss: 3.7805\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1419,\tval_loss: 3.7682\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1408,\tval_loss: 3.7661\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4469,\tval_loss: 4.0058\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1953,\tval_loss: 3.7907\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1916,\tval_loss: 3.9456\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1602,\tval_loss: 3.7320\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2179,\tval_loss: 3.9877\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1639,\tval_loss: 3.9616\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1058,\tval_loss: 3.7585\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0711,\tval_loss: 3.6168\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1928,\tval_loss: 3.7986\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2755,\tval_loss: 3.8623\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1890,\tval_loss: 3.8833\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1708,\tval_loss: 3.9945\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.4352,\tval_loss: 3.9945\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2124,\tval_loss: 3.9007\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1607,\tval_loss: 3.9945\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1638,\tval_loss: 3.9886\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2751,\tval_loss: 3.9945\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2040,\tval_loss: 3.9945\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3570,\tval_loss: 3.7519\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1201,\tval_loss: 3.8371\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1314,\tval_loss: 3.5524\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1287,\tval_loss: 3.4678\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1504,\tval_loss: 3.8197\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1976,\tval_loss: 3.6451\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2449,\tval_loss: 3.6659\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1532,\tval_loss: 3.5952\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2194,\tval_loss: 3.6924\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1788,\tval_loss: 3.8920\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2037,\tval_loss: 3.8859\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1695,\tval_loss: 3.9704\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2243,\tval_loss: 3.9687\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2095,\tval_loss: 3.9564\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4458,\tval_loss: 3.6193\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1527,\tval_loss: 3.6954\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0755,\tval_loss: 3.5421\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0848,\tval_loss: 3.5032\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0875,\tval_loss: 3.4992\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1329,\tval_loss: 3.8406\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2321,\tval_loss: 3.7731\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2016,\tval_loss: 3.6908\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2287,\tval_loss: 3.7313\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2263,\tval_loss: 3.6862\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1588,\tval_loss: 3.5927\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1372,\tval_loss: 3.5218\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1099,\tval_loss: 3.6263\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1444,\tval_loss: 3.7192\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2809,\tval_loss: 3.7881\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4920,\tval_loss: 3.5839\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1918,\tval_loss: 3.6002\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1332,\tval_loss: 3.5173\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0953,\tval_loss: 3.6028\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1140,\tval_loss: 3.5593\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1005,\tval_loss: 3.3941\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0820,\tval_loss: 3.4140\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1001,\tval_loss: 3.5751\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0363,\tval_loss: 3.3449\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2347,\tval_loss: 3.5892\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0288,\tval_loss: 3.4593\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1108,\tval_loss: 3.4532\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2844,\tval_loss: 3.5597\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.7287,\tval_loss: 3.4973\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.3795,\tval_loss: 3.6335\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.3334,\tval_loss: 3.6151\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.4745,\tval_loss: 3.5534\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2337,\tval_loss: 3.6808\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2021,\tval_loss: 3.6808\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5673,\tval_loss: 3.7383\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1378,\tval_loss: 3.6369\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1998,\tval_loss: 3.5298\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2347,\tval_loss: 3.8152\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2147,\tval_loss: 3.7570\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1563,\tval_loss: 3.7072\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0684,\tval_loss: 3.5542\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0931,\tval_loss: 3.4599\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0664,\tval_loss: 3.6070\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1490,\tval_loss: 3.7212\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1210,\tval_loss: 3.5198\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2471,\tval_loss: 3.7362\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.4165,\tval_loss: 3.8068\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.6068,\tval_loss: 3.7304\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2549,\tval_loss: 3.8118\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1684,\tval_loss: 3.6120\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2202,\tval_loss: 3.7935\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.3954,\tval_loss: 3.7992\n",
      "Iteration 4, Average C-index: 0.7167376592834345, Average IBS: 0.09124460819392537\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4373,\tval_loss: 3.4761\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1828,\tval_loss: 3.5221\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1396,\tval_loss: 3.4876\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1236,\tval_loss: 3.4643\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0167,\tval_loss: 3.4994\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0442,\tval_loss: 3.5429\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0161,\tval_loss: 3.4357\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0071,\tval_loss: 3.5745\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1164,\tval_loss: 3.5548\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1336,\tval_loss: 3.5124\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0190,\tval_loss: 3.5419\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0164,\tval_loss: 3.5078\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 3.9899,\tval_loss: 3.3884\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1968,\tval_loss: 3.5548\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.0709,\tval_loss: 3.4496\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0463,\tval_loss: 3.4556\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1918,\tval_loss: 3.5205\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0949,\tval_loss: 3.4654\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0748,\tval_loss: 3.5827\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0837,\tval_loss: 3.5173\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.0623,\tval_loss: 3.5280\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.0946,\tval_loss: 3.5375\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.0837,\tval_loss: 3.5644\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5003,\tval_loss: 3.9209\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2879,\tval_loss: 3.8801\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3000,\tval_loss: 3.7860\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1335,\tval_loss: 3.7591\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1128,\tval_loss: 3.6594\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1032,\tval_loss: 3.5633\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0542,\tval_loss: 3.7035\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0758,\tval_loss: 3.6195\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.4834,\tval_loss: 3.4819\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1081,\tval_loss: 3.9335\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3232,\tval_loss: 3.6743\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2085,\tval_loss: 3.5584\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1354,\tval_loss: 3.6528\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2584,\tval_loss: 3.7822\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0832,\tval_loss: 3.8293\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1144,\tval_loss: 3.5661\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1999,\tval_loss: 3.7591\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2829,\tval_loss: 3.6435\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1680,\tval_loss: 3.5557\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5683,\tval_loss: 3.9177\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1557,\tval_loss: 3.9162\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0979,\tval_loss: 3.9225\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1980,\tval_loss: 4.2191\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1404,\tval_loss: 4.1301\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2601,\tval_loss: 4.0704\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1439,\tval_loss: 3.9558\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2984,\tval_loss: 3.9904\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2407,\tval_loss: 4.0161\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2072,\tval_loss: 4.0164\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1493,\tval_loss: 3.8969\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1342,\tval_loss: 3.8884\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1284,\tval_loss: 3.8907\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1337,\tval_loss: 3.9861\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1162,\tval_loss: 4.0674\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2041,\tval_loss: 4.0164\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1839,\tval_loss: 4.0164\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1864,\tval_loss: 4.0164\n",
      "18:\t[0s / 3s],\t\ttrain_loss: 4.1832,\tval_loss: 4.0164\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.1911,\tval_loss: 4.0164\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1791,\tval_loss: 4.0111\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2599,\tval_loss: 4.0164\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4716,\tval_loss: 3.4765\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0672,\tval_loss: 3.6039\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1229,\tval_loss: 3.7505\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0956,\tval_loss: 3.7854\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0578,\tval_loss: 3.6085\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0306,\tval_loss: 3.4800\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1702,\tval_loss: 3.7098\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0763,\tval_loss: 3.5004\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1615,\tval_loss: 3.6206\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.3117,\tval_loss: 3.7905\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.1442,\tval_loss: 3.7321\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4208,\tval_loss: 3.7410\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1506,\tval_loss: 3.6506\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0685,\tval_loss: 3.7618\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0018,\tval_loss: 3.7207\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9747,\tval_loss: 3.6575\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.9419,\tval_loss: 3.9651\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0887,\tval_loss: 3.6831\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3118,\tval_loss: 3.7778\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.4309,\tval_loss: 3.6724\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1943,\tval_loss: 3.6548\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2764,\tval_loss: 3.6814\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1362,\tval_loss: 3.7052\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5160,\tval_loss: 3.3923\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1245,\tval_loss: 3.2994\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1678,\tval_loss: 3.5256\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1990,\tval_loss: 3.3788\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1143,\tval_loss: 3.4836\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1694,\tval_loss: 3.5174\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1212,\tval_loss: 3.3729\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2665,\tval_loss: 3.6263\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1631,\tval_loss: 3.4994\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2127,\tval_loss: 3.4440\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1840,\tval_loss: 3.5559\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1157,\tval_loss: 3.5661\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4633\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1079\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0954\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0593\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0661\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0985\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1159\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0485\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1563\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1718\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3645\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1735\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2240\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2235\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1296\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2771\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2322\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1855\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1992\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0948\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4959,\tval_loss: 3.7351\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2120,\tval_loss: 3.6828\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0492,\tval_loss: 3.6903\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1876,\tval_loss: 3.7633\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0304,\tval_loss: 4.8311\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1867,\tval_loss: 3.7156\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0920,\tval_loss: 3.6981\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.6292,\tval_loss: 3.7464\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1733,\tval_loss: 3.7649\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2165,\tval_loss: 3.6900\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2528,\tval_loss: 3.7435\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2053,\tval_loss: 3.7367\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3664,\tval_loss: 3.8912\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2031,\tval_loss: 3.8767\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2069,\tval_loss: 3.9289\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1617,\tval_loss: 3.9760\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1648,\tval_loss: 3.9168\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1682,\tval_loss: 3.9054\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1177,\tval_loss: 3.8850\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0810,\tval_loss: 3.9536\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0998,\tval_loss: 3.8607\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1201,\tval_loss: 3.8921\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1319,\tval_loss: 4.1336\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2504,\tval_loss: 3.9257\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.2482,\tval_loss: 3.9195\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2875,\tval_loss: 3.8905\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.3745,\tval_loss: 3.9885\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.4079,\tval_loss: 3.9528\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1230,\tval_loss: 3.8557\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1369,\tval_loss: 3.9610\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.3661,\tval_loss: 3.8706\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.1287,\tval_loss: 3.9079\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1406,\tval_loss: 3.8729\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1701,\tval_loss: 3.9008\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1007,\tval_loss: 3.8793\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.0666,\tval_loss: 3.9775\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1778,\tval_loss: 3.8973\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1061,\tval_loss: 3.9403\n",
      "26:\t[0s / 4s],\t\ttrain_loss: 4.0803,\tval_loss: 3.9107\n",
      "Iteration 5, Average C-index: 0.6753785606296944, Average IBS: 0.09302371533105248\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9104,\tval_loss: 3.8330\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2116,\tval_loss: 3.5944\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2567,\tval_loss: 3.8203\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2361,\tval_loss: 3.8715\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1434,\tval_loss: 3.7634\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1556,\tval_loss: 3.4426\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2785,\tval_loss: 3.8494\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1609,\tval_loss: 3.7411\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1329,\tval_loss: 3.5857\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0621,\tval_loss: 3.4764\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0525,\tval_loss: 3.4657\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1426,\tval_loss: 3.5850\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1453,\tval_loss: 4.1791\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2098,\tval_loss: 3.5213\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1586,\tval_loss: 3.6311\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1243,\tval_loss: 3.5308\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6061,\tval_loss: 3.7035\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1074,\tval_loss: 3.8219\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1218,\tval_loss: 3.5810\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1325,\tval_loss: 3.7420\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0714,\tval_loss: 3.8138\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1405,\tval_loss: 3.8626\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2742,\tval_loss: 3.8566\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1461,\tval_loss: 3.8604\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2334,\tval_loss: 3.7788\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1782,\tval_loss: 3.7239\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2164,\tval_loss: 3.9162\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2553,\tval_loss: 3.8335\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.2539,\tval_loss: 3.6487\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5229,\tval_loss: 3.6581\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1587,\tval_loss: 3.7629\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1879,\tval_loss: 3.7030\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1424,\tval_loss: 3.6806\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1498,\tval_loss: 3.7447\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1385,\tval_loss: 3.6241\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1049,\tval_loss: 3.5395\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1013,\tval_loss: 3.6068\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0816,\tval_loss: 3.5561\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1397,\tval_loss: 3.6049\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1063,\tval_loss: 3.6339\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1354,\tval_loss: 3.6424\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0633,\tval_loss: 3.5585\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2296,\tval_loss: 3.7230\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0851,\tval_loss: 3.6535\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1310,\tval_loss: 3.7029\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0380,\tval_loss: 3.6630\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5580,\tval_loss: 3.3537\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1359,\tval_loss: 3.1314\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1576,\tval_loss: 3.2166\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1297,\tval_loss: 3.2445\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2242,\tval_loss: 3.2741\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1097,\tval_loss: 3.3186\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1001,\tval_loss: 3.2905\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.5647,\tval_loss: 3.3993\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.4503,\tval_loss: 3.4628\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1893,\tval_loss: 3.3849\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2290,\tval_loss: 3.4625\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2919,\tval_loss: 3.4625\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3438\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.3289\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1622\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1819\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.1958\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.2197\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1753\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1640\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1724\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2787\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4885,\tval_loss: 3.7248\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2236,\tval_loss: 3.6612\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0965,\tval_loss: 3.7024\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1774,\tval_loss: 3.6954\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0933,\tval_loss: 3.6316\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2440,\tval_loss: 3.6967\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1759,\tval_loss: 3.6823\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0529,\tval_loss: 3.5879\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0518,\tval_loss: 3.6919\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0080,\tval_loss: 3.5171\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 3.9659,\tval_loss: 3.6005\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1374,\tval_loss: 3.6617\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1407,\tval_loss: 3.6387\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0969,\tval_loss: 3.6819\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1620,\tval_loss: 3.5478\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2327,\tval_loss: 3.5652\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1510,\tval_loss: 3.6169\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0607,\tval_loss: 3.7187\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1222,\tval_loss: 3.6927\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.1581,\tval_loss: 3.6650\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6497,\tval_loss: 4.0407\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2321,\tval_loss: 4.0542\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1371,\tval_loss: 4.0961\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2592,\tval_loss: 4.0022\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.3764,\tval_loss: 4.0932\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.3329,\tval_loss: 4.0898\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2463,\tval_loss: 4.0898\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1750,\tval_loss: 4.1201\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1647,\tval_loss: 4.0898\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2824,\tval_loss: 4.2706\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2260,\tval_loss: 4.0898\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1845,\tval_loss: 4.0898\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2189,\tval_loss: 4.0898\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1869,\tval_loss: 4.0898\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9682,\tval_loss: 3.8535\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1452,\tval_loss: 3.8178\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0740,\tval_loss: 3.7851\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1010,\tval_loss: 3.8780\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1271,\tval_loss: 3.8649\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1314,\tval_loss: 3.6754\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1801,\tval_loss: 3.7630\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2374,\tval_loss: 3.8911\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1319,\tval_loss: 3.8041\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2397,\tval_loss: 3.8185\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1552,\tval_loss: 3.9121\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.1804,\tval_loss: 3.8584\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.1916,\tval_loss: 3.7784\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0867,\tval_loss: 3.8057\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0829,\tval_loss: 3.6701\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1747,\tval_loss: 3.9490\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1212,\tval_loss: 3.9060\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1639,\tval_loss: 3.9797\n",
      "18:\t[0s / 3s],\t\ttrain_loss: 4.1662,\tval_loss: 3.9546\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.0963,\tval_loss: 3.7822\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1544,\tval_loss: 3.9405\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.5005,\tval_loss: 3.9739\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1710,\tval_loss: 3.7716\n",
      "23:\t[0s / 4s],\t\ttrain_loss: 4.0704,\tval_loss: 3.7434\n",
      "24:\t[0s / 4s],\t\ttrain_loss: 4.2531,\tval_loss: 3.7884\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.0417,\tval_loss: 3.5917\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0982,\tval_loss: 3.5300\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0571,\tval_loss: 3.7139\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1229,\tval_loss: 3.6835\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.0665,\tval_loss: 3.8724\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0481,\tval_loss: 3.7675\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2132,\tval_loss: 3.5183\n",
      "7:\t[0s / 2s],\t\ttrain_loss: 4.1125,\tval_loss: 3.5470\n",
      "8:\t[0s / 2s],\t\ttrain_loss: 4.0394,\tval_loss: 4.0465\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.1365,\tval_loss: 3.8058\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.1032,\tval_loss: 3.6994\n",
      "11:\t[0s / 3s],\t\ttrain_loss: 4.1250,\tval_loss: 3.7046\n",
      "12:\t[0s / 3s],\t\ttrain_loss: 4.1003,\tval_loss: 3.9260\n",
      "13:\t[0s / 3s],\t\ttrain_loss: 4.2525,\tval_loss: 3.5070\n",
      "14:\t[0s / 3s],\t\ttrain_loss: 4.3738,\tval_loss: 3.6488\n",
      "15:\t[0s / 4s],\t\ttrain_loss: 4.5238,\tval_loss: 3.5423\n",
      "16:\t[0s / 4s],\t\ttrain_loss: 4.2250,\tval_loss: 3.6606\n",
      "17:\t[0s / 4s],\t\ttrain_loss: 4.2072,\tval_loss: 3.5973\n",
      "18:\t[0s / 4s],\t\ttrain_loss: 4.0670,\tval_loss: 3.6093\n",
      "19:\t[0s / 4s],\t\ttrain_loss: 4.1152,\tval_loss: 3.6686\n",
      "20:\t[0s / 5s],\t\ttrain_loss: 4.0679,\tval_loss: 3.7240\n",
      "21:\t[0s / 5s],\t\ttrain_loss: 4.1431,\tval_loss: 3.5412\n",
      "22:\t[0s / 5s],\t\ttrain_loss: 4.4970,\tval_loss: 3.6451\n",
      "23:\t[0s / 5s],\t\ttrain_loss: 4.9715,\tval_loss: 3.5461\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.8322,\tval_loss: 3.6907\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1955,\tval_loss: 3.7077\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1215,\tval_loss: 3.6588\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1226,\tval_loss: 3.6962\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0827,\tval_loss: 3.6324\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0238,\tval_loss: 3.6715\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0257,\tval_loss: 3.6956\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1763,\tval_loss: 3.7885\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0601,\tval_loss: 3.6554\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0159,\tval_loss: 3.6308\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0599,\tval_loss: 3.6765\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.0540,\tval_loss: 3.8139\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.1721,\tval_loss: 3.7319\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0962,\tval_loss: 3.7190\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0604,\tval_loss: 3.6025\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1654,\tval_loss: 3.7071\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1797,\tval_loss: 3.8069\n",
      "17:\t[0s / 3s],\t\ttrain_loss: 4.1232,\tval_loss: 3.6513\n",
      "18:\t[0s / 3s],\t\ttrain_loss: 4.0586,\tval_loss: 3.5289\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.2246,\tval_loss: 3.6339\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.0949,\tval_loss: 3.5650\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2132,\tval_loss: 3.6576\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1854,\tval_loss: 3.6899\n",
      "23:\t[0s / 4s],\t\ttrain_loss: 4.1955,\tval_loss: 3.6780\n",
      "24:\t[0s / 4s],\t\ttrain_loss: 4.1522,\tval_loss: 3.6427\n",
      "25:\t[0s / 4s],\t\ttrain_loss: 4.1490,\tval_loss: 3.7126\n",
      "26:\t[0s / 4s],\t\ttrain_loss: 4.0435,\tval_loss: 3.7569\n",
      "27:\t[0s / 4s],\t\ttrain_loss: 4.0481,\tval_loss: 3.6676\n",
      "28:\t[0s / 4s],\t\ttrain_loss: 4.0827,\tval_loss: 3.6709\n",
      "Iteration 6, Average C-index: 0.6897992608768688, Average IBS: 0.09598634550032753\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9808,\tval_loss: 3.5884\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.3121,\tval_loss: 3.3370\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2403,\tval_loss: 3.5812\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.3006,\tval_loss: 3.5569\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2161,\tval_loss: 3.6558\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.2079,\tval_loss: 3.5791\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2735,\tval_loss: 3.7086\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2470,\tval_loss: 3.5360\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2180,\tval_loss: 3.5306\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2138,\tval_loss: 3.6484\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2261,\tval_loss: 3.6876\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.2055,\tval_loss: 3.6884\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7519,\tval_loss: 3.5174\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1330,\tval_loss: 3.4721\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1119,\tval_loss: 3.3498\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1343,\tval_loss: 3.4410\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0657,\tval_loss: 3.3484\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2184,\tval_loss: 3.5794\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1930,\tval_loss: 3.5295\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1016,\tval_loss: 3.2764\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1440,\tval_loss: 3.4094\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1712,\tval_loss: 3.4193\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0965,\tval_loss: 3.2696\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3509,\tval_loss: 3.3470\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0827,\tval_loss: 3.4866\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1396,\tval_loss: 3.4584\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1145,\tval_loss: 3.3494\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1217,\tval_loss: 3.4190\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.3701,\tval_loss: 3.3980\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0873,\tval_loss: 3.4339\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1241,\tval_loss: 3.3567\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.1341,\tval_loss: 3.4886\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.2081,\tval_loss: 3.3543\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9777,\tval_loss: 3.4288\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2008,\tval_loss: 3.4690\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1022,\tval_loss: 3.4404\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1958,\tval_loss: 3.5452\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.3684,\tval_loss: 3.5315\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1319,\tval_loss: 3.4065\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0467,\tval_loss: 3.4614\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1873,\tval_loss: 3.5661\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0832,\tval_loss: 3.4718\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1338,\tval_loss: 3.4248\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0860,\tval_loss: 3.4398\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.0603,\tval_loss: 3.4505\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.1622,\tval_loss: 3.4176\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1648,\tval_loss: 3.5850\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1623,\tval_loss: 3.4205\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2061,\tval_loss: 3.4443\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6671,\tval_loss: 3.7805\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1542,\tval_loss: 3.8203\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0527,\tval_loss: 3.9553\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0665,\tval_loss: 3.8302\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9953,\tval_loss: 3.8817\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0120,\tval_loss: 3.8032\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1515,\tval_loss: 3.9602\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1452,\tval_loss: 3.8846\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1144,\tval_loss: 3.9160\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1434,\tval_loss: 3.9974\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2570,\tval_loss: 3.9254\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5622,\tval_loss: 3.7882\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2441,\tval_loss: 3.7986\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1476,\tval_loss: 3.7664\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1234,\tval_loss: 3.7562\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2350,\tval_loss: 3.8322\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1553,\tval_loss: 3.7897\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1638,\tval_loss: 3.8622\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2984,\tval_loss: 3.7929\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2471,\tval_loss: 4.2140\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2693,\tval_loss: 3.8935\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2162,\tval_loss: 3.8953\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1765,\tval_loss: 3.8138\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1605,\tval_loss: 3.9352\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1629,\tval_loss: 4.4946\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3515,\tval_loss: 4.0554\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1196,\tval_loss: 4.1984\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0535,\tval_loss: 3.9634\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1663,\tval_loss: 3.9516\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0954,\tval_loss: 4.0075\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1643,\tval_loss: 4.0994\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1755,\tval_loss: 4.3022\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1227,\tval_loss: 4.1024\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0341,\tval_loss: 3.9958\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1179,\tval_loss: 3.9959\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0835,\tval_loss: 4.1027\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0854,\tval_loss: 3.9828\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0802,\tval_loss: 3.9603\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1048,\tval_loss: 4.0255\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4135\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0356\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0518\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1686\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1784\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1703\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1342\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2578\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1386\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1735\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5742,\tval_loss: 3.7565\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2580,\tval_loss: 3.8122\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1434,\tval_loss: 3.7727\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0453,\tval_loss: 3.5452\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0839,\tval_loss: 3.6123\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1279,\tval_loss: 3.7455\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0567,\tval_loss: 3.5992\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0573,\tval_loss: 3.6132\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1270,\tval_loss: 3.5707\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2294,\tval_loss: 3.8362\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1963,\tval_loss: 3.6546\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1747,\tval_loss: 3.5266\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2679,\tval_loss: 3.5397\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1885,\tval_loss: 3.7284\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2433,\tval_loss: 3.7508\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1434,\tval_loss: 3.5329\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2705,\tval_loss: 3.8729\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2336,\tval_loss: 3.8590\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2413,\tval_loss: 3.9294\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1264,\tval_loss: 3.9330\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.2678,\tval_loss: 3.8769\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2043,\tval_loss: 3.8816\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3757,\tval_loss: 3.3387\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0791,\tval_loss: 3.5376\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1628,\tval_loss: 3.7217\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0465,\tval_loss: 3.7374\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1361,\tval_loss: 3.6478\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0935,\tval_loss: 3.6414\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1400,\tval_loss: 3.5096\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1305,\tval_loss: 3.5434\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1773,\tval_loss: 3.8306\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1270,\tval_loss: 3.6627\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0990,\tval_loss: 3.6048\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5189,\tval_loss: 3.9618\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1321,\tval_loss: 3.7724\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3124,\tval_loss: 3.8100\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1867,\tval_loss: 3.8699\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1797,\tval_loss: 4.2525\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2256,\tval_loss: 3.7578\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2092,\tval_loss: 3.8575\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1444,\tval_loss: 3.7347\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1401,\tval_loss: 3.8806\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1927,\tval_loss: 3.8684\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1931,\tval_loss: 3.8512\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1793,\tval_loss: 3.8839\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1359,\tval_loss: 3.7271\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2529,\tval_loss: 3.8996\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2233,\tval_loss: 3.8734\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2076,\tval_loss: 3.8152\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0708,\tval_loss: 4.3534\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2086,\tval_loss: 3.8527\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1355,\tval_loss: 3.7548\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1124,\tval_loss: 3.7155\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.0953,\tval_loss: 3.8902\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2563,\tval_loss: 3.8964\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1077,\tval_loss: 3.8004\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.2018,\tval_loss: 3.9065\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1746,\tval_loss: 3.9480\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1491,\tval_loss: 3.8809\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.1407,\tval_loss: 3.8989\n",
      "27:\t[0s / 4s],\t\ttrain_loss: 4.1106,\tval_loss: 3.9674\n",
      "28:\t[0s / 4s],\t\ttrain_loss: 4.1439,\tval_loss: 4.0128\n",
      "29:\t[0s / 4s],\t\ttrain_loss: 4.1438,\tval_loss: 3.9866\n",
      "Iteration 7, Average C-index: 0.6871973314775264, Average IBS: 0.09180405875303035\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.8401,\tval_loss: 3.6398\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2090,\tval_loss: 3.6735\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2352,\tval_loss: 3.6534\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2405,\tval_loss: 3.6974\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1962,\tval_loss: 3.6480\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2197,\tval_loss: 3.7161\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2089,\tval_loss: 3.6746\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2264,\tval_loss: 3.6989\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1622,\tval_loss: 3.6628\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2777,\tval_loss: 3.7292\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1583,\tval_loss: 3.7563\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.6604,\tval_loss: 3.9658\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1432,\tval_loss: 3.8939\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1949,\tval_loss: 3.9360\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1961,\tval_loss: 3.9315\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1644,\tval_loss: 3.8927\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1156,\tval_loss: 4.0387\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1049,\tval_loss: 4.0370\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2018,\tval_loss: 3.9834\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1292,\tval_loss: 3.9497\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0669,\tval_loss: 3.9971\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0106,\tval_loss: 3.8866\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.0913,\tval_loss: 3.8591\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.0827,\tval_loss: 3.9055\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0308,\tval_loss: 3.9001\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0405,\tval_loss: 3.8363\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2677,\tval_loss: 4.0008\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1667,\tval_loss: 4.0166\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2630,\tval_loss: 4.0241\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2161,\tval_loss: 3.9915\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.1528,\tval_loss: 3.9349\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1910,\tval_loss: 3.9165\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1565,\tval_loss: 4.0246\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1800,\tval_loss: 3.8985\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1062,\tval_loss: 4.0544\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1351,\tval_loss: 4.0195\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4103,\tval_loss: 3.8528\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1324,\tval_loss: 3.9170\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1256,\tval_loss: 3.9985\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1405,\tval_loss: 3.7365\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2739,\tval_loss: 3.9230\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.5088,\tval_loss: 3.9345\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2124,\tval_loss: 3.8668\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1936,\tval_loss: 3.9569\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2075,\tval_loss: 3.9364\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3023,\tval_loss: 4.0246\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2353,\tval_loss: 4.0567\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2311,\tval_loss: 4.0610\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2594,\tval_loss: 4.0677\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.4043,\tval_loss: 4.0610\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3040,\tval_loss: 3.6417\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2015,\tval_loss: 3.7073\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2470,\tval_loss: 3.8712\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2089,\tval_loss: 3.8191\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1166,\tval_loss: 3.6198\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2354,\tval_loss: 3.7475\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1446,\tval_loss: 3.7021\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1412,\tval_loss: 3.7541\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1187,\tval_loss: 3.7532\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.5338,\tval_loss: 3.7037\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1321,\tval_loss: 3.8166\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1508,\tval_loss: 3.7949\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1134,\tval_loss: 3.8268\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1496,\tval_loss: 3.6401\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1015,\tval_loss: 3.8478\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3843,\tval_loss: 3.5037\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1053,\tval_loss: 3.4432\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1204,\tval_loss: 3.5523\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.4065,\tval_loss: 3.5202\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2015,\tval_loss: 3.5877\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2090,\tval_loss: 3.6335\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1633,\tval_loss: 3.3075\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0896,\tval_loss: 3.5710\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.3082,\tval_loss: 3.5176\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1938,\tval_loss: 3.5434\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2393,\tval_loss: 3.5525\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1646,\tval_loss: 3.6506\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1640,\tval_loss: 3.5885\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1924,\tval_loss: 3.4796\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.3564,\tval_loss: 3.5011\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1929,\tval_loss: 3.6181\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1750,\tval_loss: 3.6167\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4440,\tval_loss: 4.3378\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2417,\tval_loss: 4.1497\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1863,\tval_loss: 4.2455\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2497,\tval_loss: 4.5393\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2491,\tval_loss: 4.0181\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2908,\tval_loss: 4.0171\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2215,\tval_loss: 4.0022\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2099,\tval_loss: 4.0011\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1874,\tval_loss: 4.2178\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2113,\tval_loss: 4.0005\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2028,\tval_loss: 4.0020\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2115,\tval_loss: 4.0011\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2139,\tval_loss: 4.0011\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2527,\tval_loss: 4.0010\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1931,\tval_loss: 3.9947\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1950,\tval_loss: 4.0011\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1884,\tval_loss: 3.9838\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2053,\tval_loss: 4.0011\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2308,\tval_loss: 4.0266\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.4143,\tval_loss: 4.0011\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1904,\tval_loss: 4.0011\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2090,\tval_loss: 4.0011\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.2169,\tval_loss: 4.0011\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.2027,\tval_loss: 4.0011\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1879,\tval_loss: 4.0011\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1717,\tval_loss: 4.0011\n",
      "26:\t[0s / 4s],\t\ttrain_loss: 4.1815,\tval_loss: 4.0011\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.2014,\tval_loss: 3.5768\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0657,\tval_loss: 3.6007\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1384,\tval_loss: 3.5972\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0220,\tval_loss: 3.9067\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1940,\tval_loss: 3.4267\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1623,\tval_loss: 3.6369\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0848,\tval_loss: 3.5320\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0680,\tval_loss: 4.1372\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0937,\tval_loss: 3.5709\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2643,\tval_loss: 3.6921\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2044,\tval_loss: 3.6912\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2485,\tval_loss: 3.7017\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1943,\tval_loss: 3.7017\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2040,\tval_loss: 3.7017\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1892,\tval_loss: 3.7017\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6299,\tval_loss: 3.4852\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1905,\tval_loss: 3.5383\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1658,\tval_loss: 3.5163\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0687,\tval_loss: 3.5849\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1416,\tval_loss: 3.5829\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0861,\tval_loss: 3.5403\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2038,\tval_loss: 3.5030\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1721,\tval_loss: 3.5183\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1813,\tval_loss: 3.4551\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1636,\tval_loss: 3.6238\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2547,\tval_loss: 3.6036\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1543,\tval_loss: 3.6413\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1056,\tval_loss: 3.6436\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1959,\tval_loss: 3.6277\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.2644,\tval_loss: 3.6317\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1995,\tval_loss: 3.5960\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.3461,\tval_loss: 3.5243\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1866,\tval_loss: 3.6380\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1988,\tval_loss: 3.6303\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9200,\tval_loss: 3.7291\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0819,\tval_loss: 3.5132\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1124,\tval_loss: 3.6073\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0558,\tval_loss: 3.7454\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1390,\tval_loss: 3.7541\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2384,\tval_loss: 3.7676\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1743,\tval_loss: 3.7637\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1115,\tval_loss: 3.5438\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1408,\tval_loss: 3.7070\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.9804,\tval_loss: 3.6409\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0308,\tval_loss: 3.6561\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0189,\tval_loss: 3.6588\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5935,\tval_loss: 3.4574\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1725,\tval_loss: 3.3970\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1693,\tval_loss: 3.2883\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0429,\tval_loss: 3.2190\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0666,\tval_loss: 3.2451\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0557,\tval_loss: 3.3102\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1204,\tval_loss: 3.3845\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2111,\tval_loss: 3.5145\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2346,\tval_loss: 3.5490\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1835,\tval_loss: 3.3939\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1954,\tval_loss: 3.5868\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2324,\tval_loss: 3.5965\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2187,\tval_loss: 3.5628\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1965,\tval_loss: 3.5686\n",
      "Iteration 8, Average C-index: 0.6918030524825418, Average IBS: 0.09233366181505745\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5376,\tval_loss: 3.9069\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0709,\tval_loss: 3.9436\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0697,\tval_loss: 4.0234\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.3156,\tval_loss: 3.9094\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1958,\tval_loss: 3.8942\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0654,\tval_loss: 3.9161\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1542,\tval_loss: 3.9728\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1696,\tval_loss: 3.8572\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1815,\tval_loss: 4.0683\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1318,\tval_loss: 4.3714\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1830,\tval_loss: 4.0609\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1681,\tval_loss: 3.9193\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2184,\tval_loss: 4.5343\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2672,\tval_loss: 3.8905\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.2418,\tval_loss: 3.8916\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1884,\tval_loss: 3.8920\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1868,\tval_loss: 3.9000\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2448,\tval_loss: 3.8909\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5211,\tval_loss: 3.2540\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1223,\tval_loss: 3.4387\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1078,\tval_loss: 3.5143\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0938,\tval_loss: 3.5486\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1210,\tval_loss: 3.4377\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0675,\tval_loss: 3.4696\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1129,\tval_loss: 3.3063\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2316,\tval_loss: 3.5513\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1212,\tval_loss: 3.6974\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1986,\tval_loss: 4.0067\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2835,\tval_loss: 3.6350\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6024,\tval_loss: 3.6787\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2372,\tval_loss: 3.5307\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1178,\tval_loss: 3.5224\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0632,\tval_loss: 3.4073\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2267,\tval_loss: 3.8368\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2228,\tval_loss: 3.5252\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1565,\tval_loss: 3.7651\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.5083,\tval_loss: 3.5790\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2297,\tval_loss: 3.7463\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1930,\tval_loss: 3.7302\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1966,\tval_loss: 3.7520\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1232,\tval_loss: 3.6297\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1222,\tval_loss: 3.6723\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0919,\tval_loss: 3.6666\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3690\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1115\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2443\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2468\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2021\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.3435\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1805\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.6178\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1860\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1579\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4273,\tval_loss: 3.9361\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1410,\tval_loss: 3.7737\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1277,\tval_loss: 3.7903\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1071,\tval_loss: 3.9542\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1555,\tval_loss: 3.8484\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2114,\tval_loss: 3.8726\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2390,\tval_loss: 3.9266\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2164,\tval_loss: 3.8638\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1085,\tval_loss: 3.9561\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2256,\tval_loss: 3.9867\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1456,\tval_loss: 3.9421\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2116,\tval_loss: 3.9844\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5499\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0252\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1020\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0716\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1073\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0450\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1064\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.9988\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0877\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0608\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.0296,\tval_loss: 3.8128\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2104,\tval_loss: 3.7018\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0860,\tval_loss: 3.7488\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0473,\tval_loss: 3.5808\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0714,\tval_loss: 3.5769\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0541,\tval_loss: 3.6950\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0654,\tval_loss: 3.5216\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0809,\tval_loss: 3.7443\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0056,\tval_loss: 3.6883\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0670,\tval_loss: 3.6451\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0370,\tval_loss: 3.7970\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0378,\tval_loss: 3.7363\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2906,\tval_loss: 3.8634\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1247,\tval_loss: 3.6486\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1620,\tval_loss: 3.8971\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.3893,\tval_loss: 3.8612\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1478,\tval_loss: 3.6696\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3529,\tval_loss: 3.5186\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.3430,\tval_loss: 3.3210\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2105,\tval_loss: 3.4283\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2016,\tval_loss: 3.4724\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1565,\tval_loss: 3.3811\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2029,\tval_loss: 3.4322\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.3583,\tval_loss: 3.4220\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1922,\tval_loss: 3.4046\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1475,\tval_loss: 3.4025\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1442,\tval_loss: 3.2972\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1628,\tval_loss: 3.4160\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1785,\tval_loss: 3.3920\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1647,\tval_loss: 3.4020\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0929,\tval_loss: 3.4208\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1043,\tval_loss: 3.3395\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1032,\tval_loss: 3.4873\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1083,\tval_loss: 3.3836\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1593,\tval_loss: 3.2678\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.3113,\tval_loss: 3.4155\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1909,\tval_loss: 3.4608\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1973,\tval_loss: 3.3672\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.2416,\tval_loss: 3.4256\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.2762,\tval_loss: 3.3505\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1726,\tval_loss: 3.3841\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.3315,\tval_loss: 3.4814\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.2127,\tval_loss: 3.4801\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.2304,\tval_loss: 3.4419\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 4.2451,\tval_loss: 3.4862\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5795,\tval_loss: 3.5548\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1713,\tval_loss: 3.5959\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1637,\tval_loss: 3.5805\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1531,\tval_loss: 3.4428\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1588,\tval_loss: 3.6479\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1285,\tval_loss: 3.6430\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0287,\tval_loss: 3.6493\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.9596,\tval_loss: 3.5095\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1732,\tval_loss: 3.5249\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2801,\tval_loss: 3.6604\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3415,\tval_loss: 3.7049\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2320,\tval_loss: 3.7125\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2098,\tval_loss: 3.7125\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2088,\tval_loss: 3.7125\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3564,\tval_loss: 3.6518\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1763,\tval_loss: 3.6177\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1510,\tval_loss: 3.6779\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0774,\tval_loss: 3.7909\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2630,\tval_loss: 3.6365\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1542,\tval_loss: 3.8203\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1748,\tval_loss: 3.6667\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2988,\tval_loss: 3.9125\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 5.5475,\tval_loss: 3.8631\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1994,\tval_loss: 3.8633\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2165,\tval_loss: 3.7556\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2181,\tval_loss: 3.7597\n",
      "Iteration 9, Average C-index: 0.6691038132034268, Average IBS: 0.09371565514270906\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4295,\tval_loss: 3.5297\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1243,\tval_loss: 3.5432\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1130,\tval_loss: 3.6118\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1947,\tval_loss: 3.3668\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2086,\tval_loss: 3.6109\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.2352,\tval_loss: 3.5315\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1633,\tval_loss: 3.5919\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1772,\tval_loss: 3.4742\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.4995,\tval_loss: 3.6689\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2523,\tval_loss: 3.6396\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1879,\tval_loss: 3.7060\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.2301,\tval_loss: 3.6033\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.2006,\tval_loss: 3.7344\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2891,\tval_loss: 3.5910\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4784,\tval_loss: 3.7675\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2053,\tval_loss: 3.6826\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3548,\tval_loss: 3.7213\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2296,\tval_loss: 3.6528\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.0686,\tval_loss: 3.6808\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1186,\tval_loss: 3.7697\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1248,\tval_loss: 3.7842\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1207,\tval_loss: 3.7552\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0796,\tval_loss: 3.9230\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.0225,\tval_loss: 3.8355\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.0770,\tval_loss: 3.5639\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.2783,\tval_loss: 3.8114\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.1235,\tval_loss: 3.7696\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2444,\tval_loss: 3.7725\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2667,\tval_loss: 3.7862\n",
      "15:\t[0s / 3s],\t\ttrain_loss: 4.3029,\tval_loss: 3.7902\n",
      "16:\t[0s / 3s],\t\ttrain_loss: 4.2692,\tval_loss: 3.7912\n",
      "17:\t[0s / 3s],\t\ttrain_loss: 4.1678,\tval_loss: 3.7486\n",
      "18:\t[0s / 3s],\t\ttrain_loss: 4.1864,\tval_loss: 3.7905\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.2170,\tval_loss: 3.7919\n",
      "20:\t[0s / 4s],\t\ttrain_loss: 4.2006,\tval_loss: 3.7919\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6156,\tval_loss: 3.9777\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2941,\tval_loss: 3.7970\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1380,\tval_loss: 3.9011\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1228,\tval_loss: 3.9940\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1846,\tval_loss: 3.8923\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1180,\tval_loss: 3.8496\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1285,\tval_loss: 3.8041\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1874,\tval_loss: 3.8619\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1977,\tval_loss: 3.8949\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0795,\tval_loss: 3.8452\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.2438,\tval_loss: 3.8700\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.0629,\tval_loss: 3.9622\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9555,\tval_loss: 3.6635\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2026,\tval_loss: 3.5189\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1011,\tval_loss: 3.7577\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1808,\tval_loss: 3.6120\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.2368,\tval_loss: 3.6644\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1044,\tval_loss: 3.6023\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1017,\tval_loss: 3.5649\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1246,\tval_loss: 3.7572\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1101,\tval_loss: 3.7885\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.1163,\tval_loss: 3.6467\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 3.9128,\tval_loss: 3.5152\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 3.9864,\tval_loss: 3.4786\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.0393,\tval_loss: 3.6627\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0282,\tval_loss: 3.6107\n",
      "14:\t[0s / 3s],\t\ttrain_loss: 3.9786,\tval_loss: 3.6071\n",
      "15:\t[0s / 3s],\t\ttrain_loss: 3.9380,\tval_loss: 3.6699\n",
      "16:\t[0s / 3s],\t\ttrain_loss: 3.9771,\tval_loss: 3.5149\n",
      "17:\t[0s / 3s],\t\ttrain_loss: 3.9076,\tval_loss: 3.6222\n",
      "18:\t[0s / 4s],\t\ttrain_loss: 3.9848,\tval_loss: 3.5778\n",
      "19:\t[0s / 4s],\t\ttrain_loss: 4.0479,\tval_loss: 3.6253\n",
      "20:\t[0s / 4s],\t\ttrain_loss: 4.0418,\tval_loss: 3.6942\n",
      "21:\t[0s / 4s],\t\ttrain_loss: 4.0066,\tval_loss: 3.6273\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3199\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1801\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1388\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1827\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.1625\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1296\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0886\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0763\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0885\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.0085\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3803,\tval_loss: 3.6768\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1820,\tval_loss: 3.6890\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1554,\tval_loss: 3.5818\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0289,\tval_loss: 3.7213\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.1945,\tval_loss: 3.6734\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1388,\tval_loss: 3.5938\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2008,\tval_loss: 3.5351\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2476,\tval_loss: 3.7587\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1629,\tval_loss: 3.8212\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.4391,\tval_loss: 3.7587\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.2236,\tval_loss: 3.7596\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.2572,\tval_loss: 3.7587\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.2442,\tval_loss: 3.7587\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2166,\tval_loss: 3.7587\n",
      "14:\t[0s / 3s],\t\ttrain_loss: 4.1735,\tval_loss: 3.7587\n",
      "15:\t[0s / 3s],\t\ttrain_loss: 4.1871,\tval_loss: 3.7587\n",
      "16:\t[0s / 3s],\t\ttrain_loss: 4.1802,\tval_loss: 3.7587\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5118,\tval_loss: 3.5448\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2460,\tval_loss: 3.6699\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1842,\tval_loss: 3.6841\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1330,\tval_loss: 3.8401\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.1614,\tval_loss: 3.6450\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.2375,\tval_loss: 3.7526\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.3290,\tval_loss: 3.7651\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1168,\tval_loss: 3.6633\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1487,\tval_loss: 3.6090\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.1701,\tval_loss: 3.6686\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.1063,\tval_loss: 3.8193\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4889,\tval_loss: 3.5202\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1860,\tval_loss: 3.4576\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1349,\tval_loss: 3.5783\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.4704,\tval_loss: 3.6715\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.1880,\tval_loss: 3.8471\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.2032,\tval_loss: 3.7816\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2584,\tval_loss: 3.6637\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2376,\tval_loss: 3.6067\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1963,\tval_loss: 3.7829\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.2168,\tval_loss: 3.6543\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.1565,\tval_loss: 3.5662\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.2936,\tval_loss: 3.6465\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4161,\tval_loss: 3.9808\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2140,\tval_loss: 3.9749\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0929,\tval_loss: 3.8713\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0540,\tval_loss: 3.8993\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0514,\tval_loss: 3.9033\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0636,\tval_loss: 3.9088\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2119,\tval_loss: 3.9108\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1344,\tval_loss: 3.8905\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1929,\tval_loss: 3.9259\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1633,\tval_loss: 3.9073\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.0768,\tval_loss: 3.8287\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.1120,\tval_loss: 3.8966\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.0838,\tval_loss: 3.9060\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0126,\tval_loss: 3.9442\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0479,\tval_loss: 3.9069\n",
      "15:\t[0s / 3s],\t\ttrain_loss: 4.0187,\tval_loss: 4.2055\n",
      "16:\t[0s / 3s],\t\ttrain_loss: 4.0983,\tval_loss: 3.9974\n",
      "17:\t[0s / 3s],\t\ttrain_loss: 4.2230,\tval_loss: 3.9628\n",
      "18:\t[0s / 3s],\t\ttrain_loss: 4.1529,\tval_loss: 3.8907\n",
      "19:\t[0s / 3s],\t\ttrain_loss: 4.0764,\tval_loss: 3.9304\n",
      "20:\t[0s / 4s],\t\ttrain_loss: 4.0407,\tval_loss: 3.9018\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5123,\tval_loss: 3.9922\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1913,\tval_loss: 3.9776\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1268,\tval_loss: 4.0378\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0897,\tval_loss: 4.0025\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 4.1535,\tval_loss: 3.9935\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1482,\tval_loss: 3.8871\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1269,\tval_loss: 3.7636\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1355,\tval_loss: 4.0268\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1692,\tval_loss: 3.8968\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 4.1080,\tval_loss: 3.7496\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.1286,\tval_loss: 3.7019\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.3630,\tval_loss: 3.9108\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.1577,\tval_loss: 3.8592\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0774,\tval_loss: 4.0646\n",
      "14:\t[0s / 3s],\t\ttrain_loss: 4.1115,\tval_loss: 4.0662\n",
      "15:\t[0s / 3s],\t\ttrain_loss: 4.1986,\tval_loss: 4.0522\n",
      "16:\t[0s / 3s],\t\ttrain_loss: 4.1522,\tval_loss: 3.7562\n",
      "17:\t[0s / 3s],\t\ttrain_loss: 4.1002,\tval_loss: 3.7360\n",
      "18:\t[0s / 3s],\t\ttrain_loss: 4.0810,\tval_loss: 3.7508\n",
      "19:\t[0s / 4s],\t\ttrain_loss: 4.0622,\tval_loss: 4.0176\n",
      "20:\t[0s / 4s],\t\ttrain_loss: 4.1959,\tval_loss: 3.9591\n",
      "Iteration 10, Average C-index: 0.6943605864990041, Average IBS: 0.09290324380290152\n",
      "Overall Average C-index: 0.6939294113412207, Standard Deviation of C-index: 0.01503934602740422\n",
      "Overall Average IBS: 0.09283872003520073, Standard Deviation of IBS: 0.0012720932357818764\n"
     ]
    }
   ],
   "source": [
    "# best_params should contain keys like 'num_layers', 'units', 'dropout', etc.\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import torchtuples as tt\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "c_indices_all = []\n",
    "ibs_scores_all = []\n",
    "\n",
    "for iteration in range(10):\n",
    "    random_state = 2345 + iteration\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    c_indices = []\n",
    "    ibs_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(x_train)):\n",
    "        x_train_fold = x_train[train_idx]\n",
    "        y_train_fold = y_train[0][train_idx], y_train[1][train_idx]\n",
    "        x_val_fold = x_train[val_idx]\n",
    "        y_val_fold = y_train[0][val_idx], y_train[1][val_idx]\n",
    "\n",
    "        # Using best parameters for MLPVanilla architecture\n",
    "        in_features = x_train.shape[1]\n",
    "        out_features = 1  # assuming CoxPH model\n",
    "        num_nodes = [best_params['units']] * best_params['num_layers']\n",
    "        batch_norm = False  # set as needed\n",
    "        dropout = best_params['dropout']\n",
    "        output_bias = False  # set as needed\n",
    "\n",
    "        net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout=dropout, output_bias=output_bias)\n",
    "        model = CoxPH(net, tt.optim.Adam(lr=best_params['lr']))\n",
    "\n",
    "        # Train the model\n",
    "        batch_size =90 #best_params['batch_size']\n",
    "        epochs = 100  # Adjust as necessary\n",
    "        callbacks = [tt.callbacks.EarlyStopping()]\n",
    "        verbose = True\n",
    "\n",
    "        log = model.fit(x_train_fold, y_train_fold, batch_size, epochs, callbacks, verbose,\n",
    "                        val_data=(x_val_fold, y_val_fold), val_batch_size=batch_size)\n",
    "#         log.plot()\n",
    "        # Evaluate the model\n",
    "        _ = model.compute_baseline_hazards()\n",
    "        surv = model.predict_surv_df(x_test)\n",
    "        # surv = model.predict_surv_df(x_val_fold)\n",
    "        # ev = EvalSurv(surv, y_val_fold[0], y_val_fold[1], censor_surv='km')\n",
    "        ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
    "\n",
    "        # Compute C-index and IBS\n",
    "        c_index = ev.concordance_td()\n",
    "        c_indices.append(c_index)\n",
    "#         time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "        time_grid = np.linspace(y_val_fold[0].min(), y_val_fold[0].max(), 100)\n",
    "        ibs = ev.integrated_brier_score(time_grid)\n",
    "        ibs_scores.append(ibs)\n",
    "\n",
    "    c_indices_all.append(np.mean(c_indices))\n",
    "    ibs_scores_all.append(np.mean(ibs_scores))\n",
    "\n",
    "    print(f'Iteration {iteration+1}, Average C-index: {np.mean(c_indices)}, Average IBS: {np.mean(ibs_scores)}')\n",
    "\n",
    "# Calculate the overall average and standard deviation outside the iterations loop\n",
    "final_avg_c_index = np.mean(c_indices_all)\n",
    "std_dev_c_index = np.std(c_indices_all)\n",
    "\n",
    "final_avg_ibs = np.mean(ibs_scores_all)\n",
    "std_dev_ibs = np.std(ibs_scores_all)\n",
    "\n",
    "print(f'Overall Average C-index: {final_avg_c_index}, Standard Deviation of C-index: {std_dev_c_index}')\n",
    "print(f'Overall Average IBS: {final_avg_ibs}, Standard Deviation of IBS: {std_dev_ibs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31c6e366",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3834,\tval_loss: 4.0048\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0993,\tval_loss: 3.7850\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1348,\tval_loss: 3.8289\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2329,\tval_loss: 3.9487\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1762,\tval_loss: 3.9232\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1563,\tval_loss: 3.8310\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1109,\tval_loss: 3.9706\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3689,\tval_loss: 3.8687\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.5764,\tval_loss: 3.9646\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3074,\tval_loss: 4.0792\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3860,\tval_loss: 3.9636\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2147,\tval_loss: 3.9636\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3590,\tval_loss: 3.7765\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1790,\tval_loss: 3.5082\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2244,\tval_loss: 3.9036\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.5501,\tval_loss: 3.7511\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2012,\tval_loss: 3.7544\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2210,\tval_loss: 3.7625\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2101,\tval_loss: 4.0380\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1968,\tval_loss: 3.7498\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2096,\tval_loss: 3.7498\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2293,\tval_loss: 3.7341\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2563,\tval_loss: 3.7495\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2456,\tval_loss: 3.7498\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4131,\tval_loss: 3.6555\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2649,\tval_loss: 3.7050\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1712,\tval_loss: 3.7460\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1543,\tval_loss: 3.6680\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1617,\tval_loss: 3.3858\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1880,\tval_loss: 3.7544\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1873,\tval_loss: 3.7188\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2433,\tval_loss: 3.6993\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1573,\tval_loss: 3.6476\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1037,\tval_loss: 3.3781\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1184,\tval_loss: 3.4799\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0998,\tval_loss: 3.2883\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2306,\tval_loss: 3.4922\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0501,\tval_loss: 3.4205\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.0799,\tval_loss: 3.2961\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1320,\tval_loss: 3.4675\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1331,\tval_loss: 3.5779\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 6.5137,\tval_loss: 3.7542\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 5.1061,\tval_loss: 3.7542\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.3902,\tval_loss: 3.6918\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1741,\tval_loss: 3.7244\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.0994,\tval_loss: 3.5104\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4147,\tval_loss: 3.9976\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0888,\tval_loss: 3.9510\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1079,\tval_loss: 3.8925\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1387,\tval_loss: 4.0618\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2186,\tval_loss: 4.0471\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0965,\tval_loss: 4.0725\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0384,\tval_loss: 4.0234\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1388,\tval_loss: 4.0696\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.3619,\tval_loss: 4.0275\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1756,\tval_loss: 4.0064\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1232,\tval_loss: 3.9474\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1656,\tval_loss: 3.9644\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1952,\tval_loss: 4.0525\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.3089,\tval_loss: 3.8459\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2577,\tval_loss: 3.9829\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2138,\tval_loss: 3.5941\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1083,\tval_loss: 3.7483\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2523,\tval_loss: 3.6821\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1314,\tval_loss: 3.7367\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0691,\tval_loss: 3.6248\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0768,\tval_loss: 3.7307\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1733,\tval_loss: 3.6739\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1214,\tval_loss: 3.6927\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0720,\tval_loss: 3.6286\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0354,\tval_loss: 3.6452\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2251,\tval_loss: 3.6871\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5075,\tval_loss: 3.7936\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0630,\tval_loss: 4.0861\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2233,\tval_loss: 3.7581\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.3030,\tval_loss: 3.7686\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1368,\tval_loss: 3.7060\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.2914,\tval_loss: 3.6586\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.4194,\tval_loss: 3.7180\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2987,\tval_loss: 3.7812\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.3780,\tval_loss: 3.7993\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1857,\tval_loss: 3.7693\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2487,\tval_loss: 3.7093\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1578,\tval_loss: 3.7469\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.1777,\tval_loss: 3.9160\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2007,\tval_loss: 3.7499\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1595,\tval_loss: 3.6913\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1972,\tval_loss: 3.7235\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5204,\tval_loss: 3.5226\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2255,\tval_loss: 3.5489\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1239,\tval_loss: 3.6295\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.3069,\tval_loss: 3.5009\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0306,\tval_loss: 3.4327\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.3182,\tval_loss: 3.5363\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1589,\tval_loss: 3.4936\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0313,\tval_loss: 3.3932\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1129,\tval_loss: 3.5785\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0796,\tval_loss: 3.5284\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1344,\tval_loss: 3.5113\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0950,\tval_loss: 3.3762\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 3.9939,\tval_loss: 3.4581\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1379,\tval_loss: 3.4886\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1649,\tval_loss: 3.4453\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1232,\tval_loss: 3.5239\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0686,\tval_loss: 3.5743\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1926,\tval_loss: 3.5290\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0810,\tval_loss: 3.5458\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1561,\tval_loss: 3.4931\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1272,\tval_loss: 3.5927\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.1179,\tval_loss: 3.5694\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.2908,\tval_loss: 3.6085\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1997,\tval_loss: 3.6156\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1364,\tval_loss: 3.5584\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1491,\tval_loss: 3.7102\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2444,\tval_loss: 3.5906\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1621,\tval_loss: 3.5989\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2307,\tval_loss: 3.6135\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2027,\tval_loss: 3.8987\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2456,\tval_loss: 3.5202\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1700,\tval_loss: 3.5653\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1601,\tval_loss: 3.5979\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1609,\tval_loss: 3.8259\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.6100,\tval_loss: 3.5669\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.3901,\tval_loss: 3.5787\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2569,\tval_loss: 3.5443\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.4148,\tval_loss: 3.5050\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0673,\tval_loss: 3.6527\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0960,\tval_loss: 3.5685\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.6509,\tval_loss: 3.6166\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1172,\tval_loss: 3.5391\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1205,\tval_loss: 3.6272\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1193,\tval_loss: 3.5506\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1118,\tval_loss: 3.6605\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1266,\tval_loss: 3.4895\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.0592,\tval_loss: 3.5236\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.0522,\tval_loss: 3.5004\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.1468,\tval_loss: 3.4175\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 4.0956,\tval_loss: 3.4688\n",
      "28:\t[0s / 4s],\t\ttrain_loss: 3.9938,\tval_loss: 3.7105\n",
      "29:\t[0s / 4s],\t\ttrain_loss: 4.0730,\tval_loss: 3.5499\n",
      "30:\t[0s / 4s],\t\ttrain_loss: 4.1995,\tval_loss: 3.6062\n",
      "31:\t[0s / 4s],\t\ttrain_loss: 4.2197,\tval_loss: 3.5635\n",
      "32:\t[0s / 4s],\t\ttrain_loss: 4.9532,\tval_loss: 3.6484\n",
      "33:\t[0s / 4s],\t\ttrain_loss: 4.2037,\tval_loss: 3.6239\n",
      "34:\t[0s / 4s],\t\ttrain_loss: 4.1944,\tval_loss: 3.6129\n",
      "35:\t[0s / 5s],\t\ttrain_loss: 4.2227,\tval_loss: 3.5349\n",
      "36:\t[0s / 5s],\t\ttrain_loss: 4.3213,\tval_loss: 3.5098\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5855,\tval_loss: 3.9250\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2020,\tval_loss: 3.9902\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0352,\tval_loss: 3.9186\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0422,\tval_loss: 3.8954\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2136,\tval_loss: 4.1020\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1874,\tval_loss: 3.9959\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2479,\tval_loss: 4.0203\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2112,\tval_loss: 3.9926\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2603,\tval_loss: 4.0361\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0826,\tval_loss: 3.7689\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1739,\tval_loss: 4.0292\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0988,\tval_loss: 4.0046\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1143,\tval_loss: 3.9660\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0591,\tval_loss: 3.9435\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.2192,\tval_loss: 3.9452\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2182,\tval_loss: 3.9888\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2317,\tval_loss: 4.0267\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.3655,\tval_loss: 4.0928\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1848,\tval_loss: 4.0917\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.3140,\tval_loss: 4.1567\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.6824,\tval_loss: 3.7045\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1757,\tval_loss: 3.7167\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1611,\tval_loss: 3.6087\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1563,\tval_loss: 3.6370\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 3.9846,\tval_loss: 3.6131\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0616,\tval_loss: 3.6549\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0018,\tval_loss: 3.6487\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1005,\tval_loss: 3.7991\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0961,\tval_loss: 3.5503\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0004,\tval_loss: 3.7125\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0972,\tval_loss: 3.6066\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0847,\tval_loss: 3.5152\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0962,\tval_loss: 3.7437\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0813,\tval_loss: 3.6101\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.2410,\tval_loss: 3.6155\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0735,\tval_loss: 3.6676\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1303,\tval_loss: 3.8086\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2695,\tval_loss: 3.8982\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.5444,\tval_loss: 3.8210\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1558,\tval_loss: 3.8210\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1972,\tval_loss: 3.8210\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.1960,\tval_loss: 3.8210\n",
      "Iteration 1, Average C-index: 0.7051354659115452, Average IBS: 0.09078387127880191\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3118,\tval_loss: 3.7438\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2042,\tval_loss: 3.6873\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1053,\tval_loss: 3.6026\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0458,\tval_loss: 3.5313\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1522,\tval_loss: 3.8452\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1521,\tval_loss: 3.6232\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1328,\tval_loss: 3.6886\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1727,\tval_loss: 3.7248\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.7645,\tval_loss: 3.7464\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3834,\tval_loss: 3.7630\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2571,\tval_loss: 3.7456\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1930,\tval_loss: 3.7442\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1693,\tval_loss: 4.4117\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2126,\tval_loss: 3.7460\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4998,\tval_loss: 3.8387\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1141,\tval_loss: 3.7837\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0588,\tval_loss: 4.0081\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2451,\tval_loss: 3.8003\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1913,\tval_loss: 3.6803\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1594,\tval_loss: 3.7184\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1153,\tval_loss: 3.9212\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0971,\tval_loss: 3.6938\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0940,\tval_loss: 4.1121\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2339,\tval_loss: 3.7166\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1533,\tval_loss: 3.7056\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1592,\tval_loss: 3.7018\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1733,\tval_loss: 3.9037\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0782,\tval_loss: 3.7338\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.0345,\tval_loss: 3.7939\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3664,\tval_loss: 3.6122\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1375,\tval_loss: 3.7256\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0751,\tval_loss: 3.6552\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1003,\tval_loss: 3.8191\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2819,\tval_loss: 3.8586\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2224,\tval_loss: 3.8492\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 3.8914\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1311,\tval_loss: 3.7586\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1569,\tval_loss: 3.7149\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1499,\tval_loss: 3.6684\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2080,\tval_loss: 3.7668\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.6767,\tval_loss: 3.7963\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1195,\tval_loss: 3.7716\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0399,\tval_loss: 3.7861\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0542,\tval_loss: 3.7236\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0332,\tval_loss: 3.9385\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0206,\tval_loss: 3.9624\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1410,\tval_loss: 3.9930\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0796,\tval_loss: 3.6656\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1182,\tval_loss: 3.8989\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3492,\tval_loss: 3.8435\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1774,\tval_loss: 3.8479\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1700,\tval_loss: 3.8115\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 3.9712,\tval_loss: 3.6383\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1124,\tval_loss: 3.7341\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.0609,\tval_loss: 3.6177\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0169,\tval_loss: 3.6013\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0925,\tval_loss: 3.8062\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1325,\tval_loss: 3.8659\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.3320,\tval_loss: 3.9035\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1617,\tval_loss: 3.8907\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1377,\tval_loss: 3.9200\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1426,\tval_loss: 3.7541\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1322,\tval_loss: 3.6848\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1790,\tval_loss: 3.7746\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1490,\tval_loss: 3.9620\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.2579,\tval_loss: 4.0838\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4202,\tval_loss: 3.7797\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1206,\tval_loss: 3.7133\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1482,\tval_loss: 3.6100\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1028,\tval_loss: 3.8341\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1213,\tval_loss: 3.7669\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1686,\tval_loss: 3.7259\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2104,\tval_loss: 3.8697\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1897,\tval_loss: 3.7966\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1489,\tval_loss: 3.9252\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2772,\tval_loss: 3.5902\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1898,\tval_loss: 3.7177\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1085,\tval_loss: 3.7163\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2274,\tval_loss: 3.7245\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1131,\tval_loss: 3.7717\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.2241,\tval_loss: 3.5804\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1380,\tval_loss: 3.8597\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2969,\tval_loss: 3.9096\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2192,\tval_loss: 3.9092\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1455,\tval_loss: 3.8453\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1372,\tval_loss: 3.8772\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.4484,\tval_loss: 3.8888\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.4043,\tval_loss: 3.8881\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.2277,\tval_loss: 3.8882\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 5.8685,\tval_loss: 3.8895\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1678,\tval_loss: 3.8877\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3584,\tval_loss: 3.7664\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1131,\tval_loss: 3.8661\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0783,\tval_loss: 3.6676\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1483,\tval_loss: 3.8568\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1057,\tval_loss: 3.8636\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1702,\tval_loss: 3.7768\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2652,\tval_loss: 3.7624\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1571,\tval_loss: 3.9192\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1997,\tval_loss: 3.9185\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2054,\tval_loss: 3.9200\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1852,\tval_loss: 3.9200\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2128,\tval_loss: 3.9185\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.4812,\tval_loss: 3.9202\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6119,\tval_loss: 3.4691\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1593,\tval_loss: 3.3661\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1319,\tval_loss: 3.3829\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1571,\tval_loss: 3.4456\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1075,\tval_loss: 3.4870\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1251,\tval_loss: 3.5260\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0449,\tval_loss: 3.2991\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0722,\tval_loss: 3.4349\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0076,\tval_loss: 3.3390\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0392,\tval_loss: 3.2698\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2774,\tval_loss: 3.5319\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2500,\tval_loss: 3.5557\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1691,\tval_loss: 3.5972\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1377,\tval_loss: 3.6371\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1152,\tval_loss: 3.4349\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1073,\tval_loss: 3.4053\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1372,\tval_loss: 3.6452\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2347,\tval_loss: 3.5969\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1212,\tval_loss: 3.5296\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0918,\tval_loss: 3.3633\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5090,\tval_loss: 3.7533\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1286,\tval_loss: 3.8408\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2772,\tval_loss: 3.7153\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1079,\tval_loss: 3.8144\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.4655,\tval_loss: 3.8135\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2616,\tval_loss: 3.8737\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2530,\tval_loss: 3.8906\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0999,\tval_loss: 3.8458\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2292,\tval_loss: 3.8276\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1138,\tval_loss: 3.8995\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3624,\tval_loss: 3.9644\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1987,\tval_loss: 3.9322\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1610,\tval_loss: 3.9089\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4684,\tval_loss: 3.9277\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1904,\tval_loss: 3.8574\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1496,\tval_loss: 3.9817\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1022,\tval_loss: 3.8335\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2242,\tval_loss: 3.8599\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2682,\tval_loss: 3.9493\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2756,\tval_loss: 4.0037\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2105,\tval_loss: 3.9429\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2008,\tval_loss: 3.9429\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2287,\tval_loss: 3.9429\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1904,\tval_loss: 3.9429\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1847,\tval_loss: 3.9429\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2393,\tval_loss: 3.9429\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1894,\tval_loss: 3.9429\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3849,\tval_loss: 3.6335\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2129,\tval_loss: 3.7916\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2525,\tval_loss: 3.7754\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1380,\tval_loss: 3.7674\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1494,\tval_loss: 3.7079\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1458,\tval_loss: 3.7362\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0571,\tval_loss: 3.5837\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0690,\tval_loss: 3.5978\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0472,\tval_loss: 3.6294\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1113,\tval_loss: 3.8050\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1743,\tval_loss: 3.8339\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1718,\tval_loss: 3.8300\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2118,\tval_loss: 3.8265\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1710,\tval_loss: 3.7720\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.5699,\tval_loss: 3.8623\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2544,\tval_loss: 3.8363\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1790,\tval_loss: 3.8347\n",
      "Iteration 2, Average C-index: 0.7191518082119459, Average IBS: 0.09169584277528649\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4170,\tval_loss: 3.6776\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1717,\tval_loss: 3.8839\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1649,\tval_loss: 3.7298\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0142,\tval_loss: 3.5623\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1923,\tval_loss: 3.6708\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1235,\tval_loss: 3.8687\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0811,\tval_loss: 3.6336\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3164,\tval_loss: 3.8053\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2127,\tval_loss: 3.8592\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1409,\tval_loss: 3.6776\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2827,\tval_loss: 3.8835\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2145,\tval_loss: 3.8832\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2528,\tval_loss: 3.8832\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2140,\tval_loss: 3.8832\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4174,\tval_loss: 3.8409\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0408,\tval_loss: 3.8608\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1208,\tval_loss: 4.1022\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2034,\tval_loss: 3.6388\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2004,\tval_loss: 3.9818\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1429,\tval_loss: 3.8959\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1566,\tval_loss: 3.8689\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1888,\tval_loss: 3.9892\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1356,\tval_loss: 4.0532\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1730,\tval_loss: 3.8786\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2150,\tval_loss: 3.9568\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1625,\tval_loss: 3.9746\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1301,\tval_loss: 3.8317\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1438,\tval_loss: 3.7474\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5900,\tval_loss: 4.0883\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1336,\tval_loss: 4.0585\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0893,\tval_loss: 4.0908\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0921,\tval_loss: 3.9682\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0752,\tval_loss: 4.0024\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2690,\tval_loss: 3.9354\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1248,\tval_loss: 4.0240\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 4.1015,\tval_loss: 4.4402\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2837,\tval_loss: 3.9766\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2574,\tval_loss: 3.9548\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2058,\tval_loss: 3.9168\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2976,\tval_loss: 4.0693\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1192,\tval_loss: 4.0774\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1140,\tval_loss: 3.9055\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1118,\tval_loss: 3.9272\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2112,\tval_loss: 3.9679\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1373,\tval_loss: 4.0754\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0818,\tval_loss: 4.3320\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0737,\tval_loss: 3.9409\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0842,\tval_loss: 4.1973\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.0792,\tval_loss: 4.3137\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.1887,\tval_loss: 4.0564\n",
      "22:\t[0s / 2s],\t\ttrain_loss: 4.0781,\tval_loss: 3.9991\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.0911,\tval_loss: 4.2487\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4274,\tval_loss: 3.4784\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1572,\tval_loss: 3.4357\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1607,\tval_loss: 3.6558\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1274,\tval_loss: 3.5472\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0602,\tval_loss: 3.5674\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1920,\tval_loss: 3.4489\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2444,\tval_loss: 3.5693\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2443,\tval_loss: 3.5941\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1739,\tval_loss: 3.6609\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2216,\tval_loss: 3.6191\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1865,\tval_loss: 3.4253\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1274,\tval_loss: 3.4085\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0979,\tval_loss: 3.6024\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0719,\tval_loss: 3.2776\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1523,\tval_loss: 3.5342\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1118,\tval_loss: 3.4242\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0926,\tval_loss: 3.5268\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0207,\tval_loss: 3.3089\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1188,\tval_loss: 3.4676\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2874,\tval_loss: 3.8083\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.2278,\tval_loss: 3.7795\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2192,\tval_loss: 3.7845\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.2373,\tval_loss: 3.7313\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.2165,\tval_loss: 3.7235\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4543,\tval_loss: 3.7761\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1321,\tval_loss: 3.7896\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0310,\tval_loss: 3.7829\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0653,\tval_loss: 3.5292\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1008,\tval_loss: 3.5953\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1895,\tval_loss: 3.6941\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2245,\tval_loss: 3.8035\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1749,\tval_loss: 3.7807\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1323,\tval_loss: 3.7139\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2181,\tval_loss: 3.6271\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1663,\tval_loss: 3.6979\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0902,\tval_loss: 3.6570\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.3127,\tval_loss: 3.5789\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.3346,\tval_loss: 3.8094\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4721,\tval_loss: 4.0288\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1334,\tval_loss: 3.9029\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0701,\tval_loss: 3.7605\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0461,\tval_loss: 3.8914\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0642,\tval_loss: 3.8243\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0658,\tval_loss: 3.8559\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1548,\tval_loss: 4.2565\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2940,\tval_loss: 3.9176\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2420,\tval_loss: 3.8857\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3838,\tval_loss: 3.9483\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2810,\tval_loss: 3.9485\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3006,\tval_loss: 3.9650\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2127,\tval_loss: 3.9485\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6720,\tval_loss: 3.8672\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1329,\tval_loss: 3.8763\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0864,\tval_loss: 3.8323\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1804,\tval_loss: 3.8408\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2031,\tval_loss: 3.8527\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1238,\tval_loss: 3.8286\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0290,\tval_loss: 3.7483\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0816,\tval_loss: 3.7675\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1082,\tval_loss: 3.8652\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1127,\tval_loss: 3.8127\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0152,\tval_loss: 3.8880\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 3.9847,\tval_loss: 3.8087\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0904,\tval_loss: 3.8140\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0812,\tval_loss: 3.8321\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1130,\tval_loss: 4.0238\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1171,\tval_loss: 3.6871\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1914,\tval_loss: 3.8636\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0214,\tval_loss: 4.0722\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0010,\tval_loss: 4.1192\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.4829,\tval_loss: 3.8877\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.3899,\tval_loss: 3.7507\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.4071,\tval_loss: 3.8991\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.8409,\tval_loss: 3.8991\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.4926,\tval_loss: 3.8991\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.3472,\tval_loss: 3.8991\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.2486,\tval_loss: 3.8991\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5960,\tval_loss: 3.9202\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2003,\tval_loss: 4.1372\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1533,\tval_loss: 4.6645\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1410,\tval_loss: 3.9387\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0894,\tval_loss: 4.1948\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1965,\tval_loss: 4.5364\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1803,\tval_loss: 3.9244\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1551,\tval_loss: 3.9453\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0933,\tval_loss: 3.8504\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1872,\tval_loss: 4.0395\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1784,\tval_loss: 3.8715\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1136,\tval_loss: 3.9402\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2105,\tval_loss: 4.0164\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0856,\tval_loss: 4.3972\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1382,\tval_loss: 4.9757\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.7270,\tval_loss: 9.3850\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1915,\tval_loss: 3.8750\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.5589,\tval_loss: 3.8811\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1654,\tval_loss: 3.8028\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.3162,\tval_loss: 3.8148\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1633,\tval_loss: 3.8295\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1510,\tval_loss: 3.8736\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1667,\tval_loss: 3.8645\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.1156,\tval_loss: 3.8000\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1279,\tval_loss: 3.7045\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1214,\tval_loss: 3.8918\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.1479,\tval_loss: 3.8632\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 4.1349,\tval_loss: 3.7830\n",
      "28:\t[0s / 4s],\t\ttrain_loss: 4.1594,\tval_loss: 3.8844\n",
      "29:\t[0s / 4s],\t\ttrain_loss: 4.1675,\tval_loss: 3.8583\n",
      "30:\t[0s / 4s],\t\ttrain_loss: 4.1264,\tval_loss: 3.8630\n",
      "31:\t[0s / 4s],\t\ttrain_loss: 4.1020,\tval_loss: 3.9634\n",
      "32:\t[0s / 4s],\t\ttrain_loss: 4.0869,\tval_loss: 3.9656\n",
      "33:\t[0s / 4s],\t\ttrain_loss: 4.0892,\tval_loss: 3.9025\n",
      "34:\t[0s / 5s],\t\ttrain_loss: 4.1398,\tval_loss: 3.7483\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4375,\tval_loss: 3.7626\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1246,\tval_loss: 3.7184\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0580,\tval_loss: 3.6230\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1398,\tval_loss: 3.7920\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2406,\tval_loss: 3.8653\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.3759,\tval_loss: 3.7934\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2447,\tval_loss: 3.6935\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1837,\tval_loss: 3.7414\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1434,\tval_loss: 3.6875\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1542,\tval_loss: 3.7344\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1655,\tval_loss: 3.8108\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2130,\tval_loss: 3.7912\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2203,\tval_loss: 3.7940\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5625,\tval_loss: 3.8392\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0225,\tval_loss: 3.7184\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1572,\tval_loss: 3.9201\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1286,\tval_loss: 3.8905\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1189,\tval_loss: 3.9070\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1035,\tval_loss: 3.9548\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2168,\tval_loss: 3.9459\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2282,\tval_loss: 3.8624\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1931,\tval_loss: 3.8902\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1722,\tval_loss: 3.9935\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3100,\tval_loss: 3.9343\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2393,\tval_loss: 3.9379\n",
      "Iteration 3, Average C-index: 0.7152366153919992, Average IBS: 0.09086123980143133\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.2911,\tval_loss: 3.5951\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1767,\tval_loss: 4.3552\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1575,\tval_loss: 3.7807\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2014,\tval_loss: 3.6758\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1562,\tval_loss: 3.7820\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1869,\tval_loss: 4.0106\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2288,\tval_loss: 3.7968\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2239,\tval_loss: 3.8564\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2085,\tval_loss: 3.8503\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2344,\tval_loss: 3.8503\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1831,\tval_loss: 3.8503\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5401,\tval_loss: 3.6495\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1624,\tval_loss: 3.5613\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0527,\tval_loss: 3.8630\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0709,\tval_loss: 3.7895\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1145,\tval_loss: 3.6840\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0615,\tval_loss: 3.7731\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1118,\tval_loss: 3.5798\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1710,\tval_loss: 3.8255\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1386,\tval_loss: 3.5034\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0714,\tval_loss: 3.8355\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2811,\tval_loss: 3.8130\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1521,\tval_loss: 3.7256\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0697,\tval_loss: 3.6325\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.6476,\tval_loss: 3.7553\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1764,\tval_loss: 3.7472\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1662,\tval_loss: 3.6420\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1721,\tval_loss: 3.8644\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2248,\tval_loss: 3.8702\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1803,\tval_loss: 3.8702\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3901,\tval_loss: 3.9397\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1096,\tval_loss: 3.8759\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0782,\tval_loss: 3.9848\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1425,\tval_loss: 3.8964\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0771,\tval_loss: 3.9176\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 3.9984,\tval_loss: 3.9721\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2441,\tval_loss: 3.9762\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1076,\tval_loss: 3.9274\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2663,\tval_loss: 4.0272\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1947,\tval_loss: 4.0487\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.4374,\tval_loss: 3.9149\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1905,\tval_loss: 3.9136\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9309,\tval_loss: 3.5685\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2137,\tval_loss: 3.6621\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1663,\tval_loss: 3.4524\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1201,\tval_loss: 3.6218\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1779,\tval_loss: 3.3705\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1531,\tval_loss: 3.3871\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.3132,\tval_loss: 3.5834\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2930,\tval_loss: 3.5970\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1971,\tval_loss: 3.5511\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1739,\tval_loss: 3.5446\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2577,\tval_loss: 3.5907\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2062,\tval_loss: 3.5393\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.9338,\tval_loss: 3.5299\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.6341,\tval_loss: 3.5824\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2886,\tval_loss: 3.5824\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 5.2977,\tval_loss: 3.9060\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1352,\tval_loss: 3.5545\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2986,\tval_loss: 3.8651\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1853,\tval_loss: 3.8679\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2223,\tval_loss: 3.8639\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.3692,\tval_loss: 3.8054\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2401,\tval_loss: 3.8624\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2700,\tval_loss: 3.8699\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1879,\tval_loss: 3.8699\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2176,\tval_loss: 3.8699\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1899,\tval_loss: 3.8699\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2444,\tval_loss: 3.8699\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3991,\tval_loss: 3.7392\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1978,\tval_loss: 3.8096\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0953,\tval_loss: 3.7651\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0898,\tval_loss: 3.6237\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0648,\tval_loss: 3.7517\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1082,\tval_loss: 3.7998\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2114,\tval_loss: 3.6882\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2176,\tval_loss: 3.6755\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2669,\tval_loss: 3.8786\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2269,\tval_loss: 3.8413\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1647,\tval_loss: 3.7994\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1286,\tval_loss: 3.8215\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0989,\tval_loss: 3.6201\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1093,\tval_loss: 3.7501\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1243,\tval_loss: 3.5898\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1121,\tval_loss: 3.6858\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1644,\tval_loss: 3.8734\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2463,\tval_loss: 3.8805\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2832,\tval_loss: 3.8790\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2164,\tval_loss: 3.7954\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.2109,\tval_loss: 3.7997\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.1881,\tval_loss: 3.8221\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1741,\tval_loss: 3.8951\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.2106,\tval_loss: 3.8459\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1348,\tval_loss: 3.6859\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5397,\tval_loss: 3.6355\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1685,\tval_loss: 3.7318\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1334,\tval_loss: 3.9345\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1657,\tval_loss: 3.8350\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1147,\tval_loss: 3.7859\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0628,\tval_loss: 3.6379\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1686,\tval_loss: 3.8840\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3089,\tval_loss: 3.8928\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2469,\tval_loss: 3.9066\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2362,\tval_loss: 3.9005\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1769,\tval_loss: 3.7885\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7668,\tval_loss: 3.6621\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1620,\tval_loss: 3.5854\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1563,\tval_loss: 3.6872\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0393,\tval_loss: 3.7883\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1548,\tval_loss: 3.6827\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1721,\tval_loss: 3.7014\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1092,\tval_loss: 3.5848\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0961,\tval_loss: 3.5868\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0706,\tval_loss: 3.6789\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0416,\tval_loss: 3.5671\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0729,\tval_loss: 3.4976\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1252,\tval_loss: 3.5739\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 3.9887,\tval_loss: 3.4321\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.3423,\tval_loss: 3.4542\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1678,\tval_loss: 3.8059\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.4298,\tval_loss: 3.7801\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.3463,\tval_loss: 3.5286\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1972,\tval_loss: 3.6576\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0843,\tval_loss: 3.5460\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0835,\tval_loss: 3.4937\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.0631,\tval_loss: 3.5274\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.0402,\tval_loss: 3.4427\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.0691,\tval_loss: 3.6565\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4462,\tval_loss: 4.0448\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1994,\tval_loss: 4.3524\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1603,\tval_loss: 4.1779\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0718,\tval_loss: 4.1277\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1657,\tval_loss: 4.3791\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0837,\tval_loss: 4.0882\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 3.9842,\tval_loss: 3.9895\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0830,\tval_loss: 4.2025\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0391,\tval_loss: 4.7765\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0966,\tval_loss: 4.0341\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0846,\tval_loss: 3.9207\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0490,\tval_loss: 3.9576\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0300,\tval_loss: 4.1773\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0581,\tval_loss: 3.9769\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 3.9804,\tval_loss: 4.1658\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.5457,\tval_loss: 4.0576\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 3.9481,\tval_loss: 4.2658\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1331,\tval_loss: 4.3337\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.2312,\tval_loss: 3.9907\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2617,\tval_loss: 4.1789\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.4180,\tval_loss: 4.0098\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.2948,\tval_loss: 3.6277\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1538,\tval_loss: 3.7709\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1746,\tval_loss: 3.4670\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1263,\tval_loss: 3.7457\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1895,\tval_loss: 3.4606\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1488,\tval_loss: 3.6290\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1610,\tval_loss: 3.5837\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1369,\tval_loss: 3.6491\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2985,\tval_loss: 3.6836\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.4213,\tval_loss: 3.6843\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1994,\tval_loss: 3.5459\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0945,\tval_loss: 3.7487\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2208,\tval_loss: 3.7226\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1132,\tval_loss: 3.4699\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.0916,\tval_loss: 3.6905\n",
      "Iteration 4, Average C-index: 0.717795949221281, Average IBS: 0.0919300800202139\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5379,\tval_loss: 3.8440\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2303,\tval_loss: 3.8739\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3455,\tval_loss: 3.6561\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1328,\tval_loss: 3.7911\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1370,\tval_loss: 3.7055\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0511,\tval_loss: 3.7487\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1103,\tval_loss: 3.7853\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1352,\tval_loss: 4.5705\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1349,\tval_loss: 3.7341\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0227,\tval_loss: 3.7745\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0818,\tval_loss: 3.8209\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1347,\tval_loss: 3.6944\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1287,\tval_loss: 3.6373\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0256,\tval_loss: 3.7377\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1052,\tval_loss: 3.7271\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0955,\tval_loss: 3.7665\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0581,\tval_loss: 3.6979\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1157,\tval_loss: 3.7954\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.6329,\tval_loss: 3.7856\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.2249,\tval_loss: 3.7841\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1473,\tval_loss: 3.8202\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.2594,\tval_loss: 3.8534\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1063,\tval_loss: 3.8014\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5675\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1584\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0885\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0409\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0757\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2564\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2189\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1629\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1446\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.4522\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3172,\tval_loss: 3.6696\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1303,\tval_loss: 3.7940\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 3.9791,\tval_loss: 3.7680\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0154,\tval_loss: 3.6888\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0904,\tval_loss: 3.9110\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2696,\tval_loss: 3.8624\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1624,\tval_loss: 3.9058\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1614,\tval_loss: 4.5402\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2990,\tval_loss: 3.9665\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1423,\tval_loss: 3.8532\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0878,\tval_loss: 3.7528\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3454,\tval_loss: 3.6333\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1974,\tval_loss: 3.7941\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1936,\tval_loss: 3.6165\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0711,\tval_loss: 3.5635\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1831,\tval_loss: 3.7889\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.4897,\tval_loss: 3.6296\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1432,\tval_loss: 3.7703\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2389,\tval_loss: 3.7945\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1848,\tval_loss: 3.7340\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2131,\tval_loss: 3.8180\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1151,\tval_loss: 3.8194\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1139,\tval_loss: 3.8367\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1805,\tval_loss: 3.6126\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0677,\tval_loss: 3.7326\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5878,\tval_loss: 3.5775\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1952,\tval_loss: 3.7272\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0956,\tval_loss: 3.5456\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0693,\tval_loss: 3.7122\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0797,\tval_loss: 3.5496\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0631,\tval_loss: 3.6391\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1133,\tval_loss: 3.6742\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0381,\tval_loss: 3.5843\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1214,\tval_loss: 3.5780\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1031,\tval_loss: 3.5784\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0833,\tval_loss: 3.6344\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0317,\tval_loss: 3.6138\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1085,\tval_loss: 3.7235\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3202\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1300\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1106\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1870\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1560\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1650\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1527\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0717\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1071\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1092\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4962,\tval_loss: 3.6194\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1341,\tval_loss: 3.8380\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1777,\tval_loss: 3.8622\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1800,\tval_loss: 3.7227\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2985,\tval_loss: 3.7978\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2162,\tval_loss: 3.7506\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1860,\tval_loss: 3.7067\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1307,\tval_loss: 3.7310\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1860,\tval_loss: 3.7834\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1983,\tval_loss: 3.7413\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1253,\tval_loss: 3.8242\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6338,\tval_loss: 3.8301\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1375,\tval_loss: 3.7146\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0719,\tval_loss: 3.7371\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0748,\tval_loss: 3.7078\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1246,\tval_loss: 3.6608\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0706,\tval_loss: 3.7766\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0243,\tval_loss: 3.6701\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1267,\tval_loss: 3.7192\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9892,\tval_loss: 3.7338\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0496,\tval_loss: 3.7709\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0871,\tval_loss: 3.8682\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0085,\tval_loss: 3.8402\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0497,\tval_loss: 4.0168\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0984,\tval_loss: 3.8454\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2898,\tval_loss: 3.8043\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4768,\tval_loss: 3.4016\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1360,\tval_loss: 3.1824\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0704,\tval_loss: 3.5891\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0317,\tval_loss: 3.5349\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0411,\tval_loss: 3.3946\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0687,\tval_loss: 3.3257\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0837,\tval_loss: 3.6112\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2373,\tval_loss: 3.6471\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1045,\tval_loss: 3.5340\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3819,\tval_loss: 3.4929\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1358,\tval_loss: 3.3990\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1518,\tval_loss: 3.2735\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3408,\tval_loss: 3.6122\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1441,\tval_loss: 3.5638\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1085,\tval_loss: 3.6466\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1844,\tval_loss: 3.6821\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1629,\tval_loss: 3.7562\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1528,\tval_loss: 3.6021\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2136,\tval_loss: 3.6225\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1395,\tval_loss: 3.7758\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1517,\tval_loss: 3.5926\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1205,\tval_loss: 3.6182\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2281,\tval_loss: 3.6220\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1784,\tval_loss: 3.5814\n",
      "Iteration 5, Average C-index: 0.6921306184156848, Average IBS: 0.09277874215039497\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3308,\tval_loss: 4.8365\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2569,\tval_loss: 3.6466\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0671,\tval_loss: 3.5896\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1119,\tval_loss: 3.6901\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1982,\tval_loss: 3.7425\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1472,\tval_loss: 3.7391\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1219,\tval_loss: 3.5956\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1209,\tval_loss: 3.6361\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1790,\tval_loss: 3.7822\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1569,\tval_loss: 3.6884\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3244,\tval_loss: 3.6787\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1645,\tval_loss: 3.7008\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1751,\tval_loss: 3.7946\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3521,\tval_loss: 3.5829\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2142,\tval_loss: 3.6432\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0458,\tval_loss: 3.6503\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1776,\tval_loss: 3.6220\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2297,\tval_loss: 3.6015\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1703,\tval_loss: 3.5945\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1119,\tval_loss: 3.6242\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1112,\tval_loss: 3.7201\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1306,\tval_loss: 3.6494\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2205,\tval_loss: 3.7394\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1917,\tval_loss: 3.7494\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4453,\tval_loss: 3.6907\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1641,\tval_loss: 3.6575\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1052,\tval_loss: 3.4681\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1284,\tval_loss: 3.4996\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0476,\tval_loss: 3.4899\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.3122,\tval_loss: 3.6784\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2188,\tval_loss: 3.6162\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1156,\tval_loss: 3.5664\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1570,\tval_loss: 3.6090\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.4026,\tval_loss: 3.6197\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1815,\tval_loss: 3.6707\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1394,\tval_loss: 3.6918\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1430,\tval_loss: 3.6841\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4186,\tval_loss: 3.3680\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2147,\tval_loss: 3.4694\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1761,\tval_loss: 3.5056\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1435,\tval_loss: 3.3897\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2713,\tval_loss: 3.4685\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1202,\tval_loss: 3.3318\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0558,\tval_loss: 3.3956\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.4990,\tval_loss: 3.5720\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2465,\tval_loss: 3.4236\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1829,\tval_loss: 3.5357\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.6883,\tval_loss: 3.5200\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3057,\tval_loss: 3.5512\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2860,\tval_loss: 3.5512\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1823,\tval_loss: 3.5512\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.1877,\tval_loss: 3.5512\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1787,\tval_loss: 3.5512\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7675,\tval_loss: 3.6210\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2173,\tval_loss: 3.8445\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1630,\tval_loss: 3.7206\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0832,\tval_loss: 3.5730\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1342,\tval_loss: 3.8914\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1391,\tval_loss: 3.6992\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1583,\tval_loss: 3.7181\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1189,\tval_loss: 3.6460\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1258,\tval_loss: 3.8155\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0878,\tval_loss: 3.3521\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1011,\tval_loss: 3.6299\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1445,\tval_loss: 3.8246\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1776,\tval_loss: 3.7861\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1295,\tval_loss: 3.7815\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0721,\tval_loss: 3.7185\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1256,\tval_loss: 3.5621\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0590,\tval_loss: 3.7363\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.0777,\tval_loss: 3.7455\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0355,\tval_loss: 3.3417\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0703,\tval_loss: 3.5742\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.0425,\tval_loss: 3.7556\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 4.0300,\tval_loss: 3.5305\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.0416,\tval_loss: 3.4846\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.0288,\tval_loss: 3.5068\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.0767,\tval_loss: 3.3718\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.0195,\tval_loss: 3.4137\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.0585,\tval_loss: 3.7722\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 4.4496,\tval_loss: 3.5975\n",
      "28:\t[0s / 3s],\t\ttrain_loss: 4.2119,\tval_loss: 3.5921\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4882,\tval_loss: 3.5568\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1225,\tval_loss: 3.3427\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1720,\tval_loss: 3.4028\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1101,\tval_loss: 3.5234\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1418,\tval_loss: 3.5839\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2242,\tval_loss: 3.4002\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1294,\tval_loss: 3.5491\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2469,\tval_loss: 3.5520\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2012,\tval_loss: 3.5893\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1726,\tval_loss: 3.5690\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2012,\tval_loss: 3.5829\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3860,\tval_loss: 3.5528\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5502\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1019\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0708\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.4804\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2322\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1574\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1344\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1907\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2165\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1202\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4308,\tval_loss: 3.8121\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1396,\tval_loss: 3.8130\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0885,\tval_loss: 3.5854\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1239,\tval_loss: 3.8092\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1216,\tval_loss: 3.7293\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1274,\tval_loss: 3.8117\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0800,\tval_loss: 3.6474\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.9984,\tval_loss: 3.7716\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1070,\tval_loss: 3.9092\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1593,\tval_loss: 3.7410\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1509,\tval_loss: 3.5869\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0577,\tval_loss: 3.7706\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1496,\tval_loss: 3.8497\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3119,\tval_loss: 3.8643\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.9969,\tval_loss: 3.9377\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1753,\tval_loss: 4.0079\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1383,\tval_loss: 3.9233\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2381,\tval_loss: 3.9391\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2459,\tval_loss: 3.9479\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2288,\tval_loss: 3.9434\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2045,\tval_loss: 3.9422\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1901,\tval_loss: 3.9301\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2139,\tval_loss: 3.9342\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1498,\tval_loss: 3.9359\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3576,\tval_loss: 3.4738\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1886,\tval_loss: 3.8012\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1088,\tval_loss: 3.5779\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2331,\tval_loss: 3.7627\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1503,\tval_loss: 3.7999\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1175,\tval_loss: 3.7017\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2419,\tval_loss: 3.7298\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1135,\tval_loss: 3.6483\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1707,\tval_loss: 3.5756\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2487,\tval_loss: 3.8900\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1910,\tval_loss: 3.8900\n",
      "Iteration 6, Average C-index: 0.6983357730795998, Average IBS: 0.09239557624894515\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3588,\tval_loss: 3.7590\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.3153,\tval_loss: 3.7520\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3624,\tval_loss: 3.7223\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.3274,\tval_loss: 3.8177\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1079,\tval_loss: 3.7174\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1699,\tval_loss: 3.7615\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1584,\tval_loss: 4.0484\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3057,\tval_loss: 3.6945\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2387,\tval_loss: 3.7166\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1587,\tval_loss: 3.7133\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2139,\tval_loss: 3.7156\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2648,\tval_loss: 3.6709\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1187,\tval_loss: 3.7423\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1554,\tval_loss: 3.7281\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2780,\tval_loss: 3.7317\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1871,\tval_loss: 3.7540\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1858,\tval_loss: 3.7944\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1412,\tval_loss: 3.9260\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1987,\tval_loss: 3.6941\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1104,\tval_loss: 3.6249\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 4.1256,\tval_loss: 3.7110\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1204,\tval_loss: 3.7378\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1131,\tval_loss: 3.7416\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.0934,\tval_loss: 3.7543\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.0794,\tval_loss: 3.7644\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.0557,\tval_loss: 3.7023\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.0707,\tval_loss: 3.7413\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 4.1079,\tval_loss: 3.7324\n",
      "28:\t[0s / 4s],\t\ttrain_loss: 4.1529,\tval_loss: 3.7574\n",
      "29:\t[0s / 4s],\t\ttrain_loss: 4.0928,\tval_loss: 3.7570\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3341,\tval_loss: 3.5295\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1842,\tval_loss: 3.7478\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1793,\tval_loss: 3.4401\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2588,\tval_loss: 3.6625\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1420,\tval_loss: 3.7465\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0844,\tval_loss: 3.6038\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2392,\tval_loss: 3.7005\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1964,\tval_loss: 3.6355\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1017,\tval_loss: 3.6665\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0727,\tval_loss: 3.8421\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1594,\tval_loss: 3.6745\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0335,\tval_loss: 3.6568\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0877,\tval_loss: 3.6526\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3326,\tval_loss: 3.6872\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1453,\tval_loss: 3.5393\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2141,\tval_loss: 3.7495\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0962,\tval_loss: 3.7218\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1755,\tval_loss: 3.6812\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0878,\tval_loss: 3.5992\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1448,\tval_loss: 3.4407\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1956,\tval_loss: 3.6054\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.5861,\tval_loss: 3.6377\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3379,\tval_loss: 3.7974\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2102,\tval_loss: 3.8280\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1891,\tval_loss: 3.8280\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2279,\tval_loss: 3.8280\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2093,\tval_loss: 3.8280\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2056,\tval_loss: 3.8281\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1954,\tval_loss: 3.7411\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.3494,\tval_loss: 3.7116\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3558,\tval_loss: 3.4168\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1746,\tval_loss: 3.5650\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2222,\tval_loss: 3.5138\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0519,\tval_loss: 3.5548\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0773,\tval_loss: 3.4705\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1935,\tval_loss: 3.7087\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2600,\tval_loss: 3.6734\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2921,\tval_loss: 3.6631\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2214,\tval_loss: 3.4352\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1940,\tval_loss: 3.6635\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2495,\tval_loss: 3.6860\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5545,\tval_loss: 3.2172\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0950,\tval_loss: 3.3167\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1335,\tval_loss: 3.4194\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1309,\tval_loss: 3.5496\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1631,\tval_loss: 3.4634\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0787,\tval_loss: 3.4510\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0497,\tval_loss: 3.3218\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1474,\tval_loss: 3.4251\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1244,\tval_loss: 3.2850\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3512,\tval_loss: 3.5996\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.5768,\tval_loss: 3.6122\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7200,\tval_loss: 3.5065\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2465,\tval_loss: 3.3979\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1784,\tval_loss: 3.5359\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1963,\tval_loss: 3.5906\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2049,\tval_loss: 3.5031\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1453,\tval_loss: 3.5422\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1733,\tval_loss: 3.4351\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.3063,\tval_loss: 3.5444\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1656,\tval_loss: 3.4670\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2427,\tval_loss: 3.5162\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1307,\tval_loss: 3.5467\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0474,\tval_loss: 3.4985\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3175,\tval_loss: 3.7107\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1155,\tval_loss: 3.6897\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1523,\tval_loss: 3.6931\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2731,\tval_loss: 3.8334\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2395,\tval_loss: 3.8099\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2335,\tval_loss: 3.7995\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1453,\tval_loss: 3.8018\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1439,\tval_loss: 3.7076\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1562,\tval_loss: 3.7027\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2372,\tval_loss: 3.7308\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2030,\tval_loss: 3.8393\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2771,\tval_loss: 3.8395\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4038,\tval_loss: 3.7503\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1675,\tval_loss: 3.9923\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1399,\tval_loss: 4.1446\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1927,\tval_loss: 3.8065\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1534,\tval_loss: 3.8209\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1722,\tval_loss: 4.0699\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1416,\tval_loss: 3.7919\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1917,\tval_loss: 3.7813\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.3115,\tval_loss: 3.7564\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2030,\tval_loss: 9.2341\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.6337,\tval_loss: 4.0343\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5563,\tval_loss: 3.6222\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1036,\tval_loss: 3.4606\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1393,\tval_loss: 3.6821\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1221,\tval_loss: 3.9445\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1217,\tval_loss: 3.8300\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0464,\tval_loss: 3.3897\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0263,\tval_loss: 3.6579\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 3.9964,\tval_loss: 3.3306\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0752,\tval_loss: 3.4421\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0925,\tval_loss: 3.7705\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0236,\tval_loss: 3.6449\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1236,\tval_loss: 3.8600\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.3540,\tval_loss: 3.8175\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2584,\tval_loss: 3.8574\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1323,\tval_loss: 3.7152\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1477,\tval_loss: 3.8416\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.2688,\tval_loss: 3.7151\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 5.2893,\tval_loss: 3.7498\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4357\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1823\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1733\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1805\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2315\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1198\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1655\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1016\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2247\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0882\n",
      "Iteration 7, Average C-index: 0.7004055578219865, Average IBS: 0.09283001107937262\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9487,\tval_loss: 3.8216\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1465,\tval_loss: 3.5065\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1802,\tval_loss: 3.7184\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1256,\tval_loss: 3.8828\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1942,\tval_loss: 3.9064\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1814,\tval_loss: 3.8995\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1614,\tval_loss: 3.9056\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1351,\tval_loss: 3.8455\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1546,\tval_loss: 3.8258\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1853,\tval_loss: 3.6781\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0564,\tval_loss: 3.4874\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1116,\tval_loss: 3.7920\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1342,\tval_loss: 3.8276\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1681,\tval_loss: 3.8321\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2461,\tval_loss: 3.9183\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1992,\tval_loss: 3.9463\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.3101,\tval_loss: 3.9093\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1792,\tval_loss: 3.9114\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1905,\tval_loss: 3.8898\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1646,\tval_loss: 3.8790\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.2068,\tval_loss: 3.8605\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6224,\tval_loss: 3.8614\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2082,\tval_loss: 3.7879\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0606,\tval_loss: 3.7811\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0383,\tval_loss: 3.6412\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1247,\tval_loss: 3.7409\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0890,\tval_loss: 3.7648\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.1432,\tval_loss: 3.5979\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0994,\tval_loss: 3.6826\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1280,\tval_loss: 3.8129\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1159,\tval_loss: 3.5923\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0548,\tval_loss: 3.6227\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0708,\tval_loss: 3.6914\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.3386,\tval_loss: 3.8309\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.1461,\tval_loss: 3.8680\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1641,\tval_loss: 3.8497\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1643,\tval_loss: 3.7722\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1581,\tval_loss: 3.7557\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1509,\tval_loss: 3.8253\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1516,\tval_loss: 3.6677\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0445,\tval_loss: 3.6522\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4340,\tval_loss: 3.5537\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1042,\tval_loss: 3.3457\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0826,\tval_loss: 3.5427\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1355,\tval_loss: 3.4307\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2239,\tval_loss: 3.5166\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2039,\tval_loss: 3.5067\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2588,\tval_loss: 3.4441\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2461,\tval_loss: 3.4088\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1853,\tval_loss: 3.3451\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2167,\tval_loss: 3.5522\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1959,\tval_loss: 3.5287\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0900,\tval_loss: 3.4699\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1148,\tval_loss: 3.4845\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1266,\tval_loss: 3.4071\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1097,\tval_loss: 3.3675\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0544,\tval_loss: 3.4626\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1415,\tval_loss: 3.4095\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1564,\tval_loss: 3.5183\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0855,\tval_loss: 3.4067\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7493,\tval_loss: 3.5056\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1325,\tval_loss: 3.4986\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0708,\tval_loss: 3.5193\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2934,\tval_loss: 3.6710\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2456,\tval_loss: 3.6057\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2674,\tval_loss: 3.5898\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1378,\tval_loss: 3.6212\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1588,\tval_loss: 3.3852\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1622,\tval_loss: 3.4546\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1171,\tval_loss: 3.5014\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1184,\tval_loss: 3.5711\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0489,\tval_loss: 3.4613\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1106,\tval_loss: 3.4933\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1375,\tval_loss: 3.5388\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2167,\tval_loss: 3.5095\n",
      "15:\t[0s / 2s],\t\n",
      "16:\t[0s / 2s],\t\n",
      "17:\t[0s / 2s],\t\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3501,\tval_loss: 3.7312\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1832,\tval_loss: 3.8373\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2068,\tval_loss: 3.8379\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1197,\tval_loss: 3.7025\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1389,\tval_loss: 3.7431\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1383,\tval_loss: 3.8607\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0625,\tval_loss: 3.7082\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1089,\tval_loss: 3.8187\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2286,\tval_loss: 3.7569\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1373,\tval_loss: 3.7684\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0853,\tval_loss: 3.7669\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.3344,\tval_loss: 3.7742\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1325,\tval_loss: 3.7592\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.0380,\tval_loss: 3.7620\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3747,\tval_loss: 3.7540\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.3727,\tval_loss: 3.8257\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3146,\tval_loss: 3.7882\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.3372,\tval_loss: 3.6534\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2679,\tval_loss: 3.6634\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1693,\tval_loss: 3.7754\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0747,\tval_loss: 3.6528\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2567,\tval_loss: 3.7046\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1555,\tval_loss: 3.8046\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1897,\tval_loss: 3.9020\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2318,\tval_loss: 3.7970\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1701,\tval_loss: 3.7635\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1065,\tval_loss: 3.6864\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1525,\tval_loss: 3.7224\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2205,\tval_loss: 3.7710\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1793,\tval_loss: 3.7311\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0751,\tval_loss: 3.5155\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1738,\tval_loss: 3.6453\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1735,\tval_loss: 3.7595\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1406,\tval_loss: 3.7948\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1781,\tval_loss: 3.7766\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1108,\tval_loss: 3.6853\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1357,\tval_loss: 3.6214\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.2019,\tval_loss: 3.8488\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.1892,\tval_loss: 3.8397\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1722,\tval_loss: 3.5813\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.2444,\tval_loss: 3.8376\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3474,\tval_loss: 3.5901\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1749,\tval_loss: 3.6752\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1519,\tval_loss: 3.7214\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1033,\tval_loss: 3.5104\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1484,\tval_loss: 3.6453\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1265,\tval_loss: 3.6322\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1388,\tval_loss: 3.6951\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2247,\tval_loss: 3.8731\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1651,\tval_loss: 3.6611\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0727,\tval_loss: 3.6325\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0753,\tval_loss: 3.6838\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0664,\tval_loss: 3.6227\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1601,\tval_loss: 3.6630\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1011,\tval_loss: 3.7116\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4737,\tval_loss: 3.4048\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2467,\tval_loss: 3.2692\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0908,\tval_loss: 3.2349\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1392,\tval_loss: 3.3239\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0648,\tval_loss: 3.3251\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1273,\tval_loss: 3.2462\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1205,\tval_loss: 3.3561\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1235,\tval_loss: 3.4559\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0893,\tval_loss: 3.4347\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1260,\tval_loss: 3.4848\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2389,\tval_loss: 3.4827\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1723,\tval_loss: 3.4375\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.3172,\tval_loss: 3.4305\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4329,\tval_loss: 3.8603\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1521,\tval_loss: 3.8745\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1015,\tval_loss: 3.7750\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.3318,\tval_loss: 3.9621\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0341,\tval_loss: 3.9857\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1796,\tval_loss: 3.7538\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1325,\tval_loss: 3.8781\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1204,\tval_loss: 3.7423\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1696,\tval_loss: 3.9497\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2499,\tval_loss: 3.8459\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1811,\tval_loss: 3.8459\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2219,\tval_loss: 3.8459\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2153,\tval_loss: 3.8459\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1862,\tval_loss: 3.8459\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1760,\tval_loss: 3.8459\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2104,\tval_loss: 3.8459\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1831,\tval_loss: 3.8459\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1920,\tval_loss: 3.8459\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 6.0470,\tval_loss: 3.8616\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2234,\tval_loss: 3.7665\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0763,\tval_loss: 3.7518\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0308,\tval_loss: 3.7195\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1077,\tval_loss: 3.7584\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0315,\tval_loss: 3.7098\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0887,\tval_loss: 3.6151\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0448,\tval_loss: 3.5920\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 3.9286,\tval_loss: 3.8855\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0550,\tval_loss: 3.6030\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0089,\tval_loss: 3.7075\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 3.9975,\tval_loss: 3.7571\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 3.9839,\tval_loss: 3.8437\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 3.9190,\tval_loss: 3.6952\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 3.9866,\tval_loss: 3.9658\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 3.9695,\tval_loss: 3.8108\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 3.9433,\tval_loss: 3.7845\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 3.9717,\tval_loss: 3.8610\n",
      "Iteration 8, Average C-index: 0.7186940558181949, Average IBS: 0.09069504106259393\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3727,\tval_loss: 3.7561\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1968,\tval_loss: 3.5849\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0710,\tval_loss: 3.6327\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0738,\tval_loss: 3.7028\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2430,\tval_loss: 3.6529\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1247,\tval_loss: 3.5994\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1636,\tval_loss: 3.6535\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1048,\tval_loss: 3.6123\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1553,\tval_loss: 3.5976\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.0239,\tval_loss: 3.6388\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0687,\tval_loss: 3.7039\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0995,\tval_loss: 3.6735\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4637,\tval_loss: 3.5898\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1173,\tval_loss: 3.8033\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1106,\tval_loss: 3.6801\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0996,\tval_loss: 3.5316\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.3342,\tval_loss: 3.5997\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2834,\tval_loss: 3.8167\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2142,\tval_loss: 3.8123\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.5231,\tval_loss: 3.7754\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2559,\tval_loss: 3.7477\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3184,\tval_loss: 3.8277\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.3166,\tval_loss: 4.0334\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2447,\tval_loss: 3.8233\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.4677,\tval_loss: 3.8233\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2595,\tval_loss: 3.8233\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6317,\tval_loss: 3.6744\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.3360,\tval_loss: 3.8595\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2524,\tval_loss: 3.7846\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1279,\tval_loss: 3.7037\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0965,\tval_loss: 3.7254\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1065,\tval_loss: 3.7046\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2207,\tval_loss: 3.7200\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0341,\tval_loss: 3.4770\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0657,\tval_loss: 3.5181\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1539,\tval_loss: 3.7570\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1062,\tval_loss: 3.6871\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0237,\tval_loss: 3.6713\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0373,\tval_loss: 3.5963\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.2076,\tval_loss: 3.7377\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.0592,\tval_loss: 3.8098\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1139,\tval_loss: 3.6684\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.0973,\tval_loss: 3.8308\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.5221,\tval_loss: 3.8241\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5467,\tval_loss: 3.7899\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1302,\tval_loss: 3.8114\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1326,\tval_loss: 3.8691\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1201,\tval_loss: 3.8911\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2022,\tval_loss: 4.0040\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1807,\tval_loss: 3.8119\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.0998,\tval_loss: 3.8854\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1478,\tval_loss: 3.9642\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2013,\tval_loss: 3.8942\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1139,\tval_loss: 3.9178\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1345,\tval_loss: 3.8298\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.2649,\tval_loss: 3.8891\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2107,\tval_loss: 3.9990\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1539,\tval_loss: 4.0397\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0338,\tval_loss: 3.9290\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1209,\tval_loss: 4.0616\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2431,\tval_loss: 3.8774\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2211,\tval_loss: 4.0460\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1984,\tval_loss: 4.0433\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2124,\tval_loss: 4.0421\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1469,\tval_loss: 4.0455\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2150,\tval_loss: 4.0889\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2800,\tval_loss: 4.0681\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2367,\tval_loss: 4.0582\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1843,\tval_loss: 4.0582\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2711,\tval_loss: 4.0582\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1722,\tval_loss: 4.0582\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4952,\tval_loss: 4.0128\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1697,\tval_loss: 3.4467\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1911,\tval_loss: 3.6078\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1972,\tval_loss: 3.7088\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1045,\tval_loss: 3.5486\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1946,\tval_loss: 3.7521\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.3672,\tval_loss: 4.0075\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2083,\tval_loss: 3.7813\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1385,\tval_loss: 3.6653\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2830,\tval_loss: 3.8406\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1400,\tval_loss: 3.6927\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1580,\tval_loss: 3.8579\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3088,\tval_loss: 3.8894\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2014,\tval_loss: 3.8631\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0979,\tval_loss: 4.5386\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1516,\tval_loss: 4.7698\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1707,\tval_loss: 5.7432\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2726,\tval_loss: 3.8848\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1619,\tval_loss: 5.5190\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2591,\tval_loss: 4.4121\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2118,\tval_loss: 3.8981\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1311,\tval_loss: 3.9984\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1816,\tval_loss: 3.8923\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1637,\tval_loss: 5.2303\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4558,\tval_loss: 3.9579\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1424,\tval_loss: 3.9301\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1942,\tval_loss: 3.9674\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1989,\tval_loss: 3.9351\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2070,\tval_loss: 3.8656\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1991,\tval_loss: 3.8927\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.6048,\tval_loss: 3.9527\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1854,\tval_loss: 3.9527\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2258,\tval_loss: 3.9527\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2053,\tval_loss: 3.9527\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.1793,\tval_loss: 3.9527\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.1805,\tval_loss: 3.9528\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.2179,\tval_loss: 3.9527\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.3241,\tval_loss: 3.9527\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2847,\tval_loss: 3.9527\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5984,\tval_loss: 3.5173\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.2059,\tval_loss: 3.5612\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2691,\tval_loss: 3.4745\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1208,\tval_loss: 3.5266\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1166,\tval_loss: 3.5102\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.0603,\tval_loss: 3.3335\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0384,\tval_loss: 3.5639\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0717,\tval_loss: 3.4135\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1180,\tval_loss: 3.5374\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2404,\tval_loss: 3.8036\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 4.2006,\tval_loss: 3.7183\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.1846,\tval_loss: 3.7165\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.1601,\tval_loss: 3.7165\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1782,\tval_loss: 3.7165\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1889,\tval_loss: 3.7165\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1624,\tval_loss: 3.7165\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4836,\tval_loss: 3.6214\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1721,\tval_loss: 3.6474\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2041,\tval_loss: 3.7425\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2121,\tval_loss: 3.6494\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2701,\tval_loss: 3.7264\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 4.1739,\tval_loss: 3.8385\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1570,\tval_loss: 3.6935\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0728,\tval_loss: 3.8387\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0942,\tval_loss: 3.5388\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1944,\tval_loss: 3.6790\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1896,\tval_loss: 3.6273\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 4.1605,\tval_loss: 3.7361\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 4.2377,\tval_loss: 3.5411\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.3994,\tval_loss: 3.7556\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2837,\tval_loss: 3.7757\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2358,\tval_loss: 3.7776\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1993,\tval_loss: 3.7441\n",
      "17:\t[0s / 3s],\t\ttrain_loss: 4.2190,\tval_loss: 3.7776\n",
      "18:\t[0s / 3s],\t\ttrain_loss: 4.2185,\tval_loss: 3.7776\n",
      "Iteration 9, Average C-index: 0.7030734803580427, Average IBS: 0.09297784931360983\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5427,\tval_loss: 3.8199\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0849,\tval_loss: 3.7973\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0861,\tval_loss: 3.7705\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1044,\tval_loss: 3.7843\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0404,\tval_loss: 3.7842\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0864,\tval_loss: 3.7820\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.0170,\tval_loss: 3.7230\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0598,\tval_loss: 3.8753\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0600,\tval_loss: 3.8203\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 3.9865,\tval_loss: 3.7713\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0898,\tval_loss: 3.7026\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0681,\tval_loss: 3.7487\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1509,\tval_loss: 3.8227\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2210,\tval_loss: 3.8736\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2871,\tval_loss: 3.9044\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.3270,\tval_loss: 3.8941\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1273,\tval_loss: 3.8750\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2556,\tval_loss: 3.9029\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1667,\tval_loss: 3.8770\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1174,\tval_loss: 3.7204\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.3215,\tval_loss: 3.8954\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4969,\tval_loss: 3.7848\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1717,\tval_loss: 3.8555\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1005,\tval_loss: 3.8430\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0487,\tval_loss: 3.8147\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.0891,\tval_loss: 3.6005\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.0650,\tval_loss: 3.5270\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2431,\tval_loss: 3.8432\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1443,\tval_loss: 3.8779\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0888,\tval_loss: 3.6607\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.3514,\tval_loss: 3.7882\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.0870,\tval_loss: 3.5916\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1768,\tval_loss: 3.8586\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.2347,\tval_loss: 3.8371\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1997,\tval_loss: 3.7140\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.2605,\tval_loss: 3.9418\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.0999,\tval_loss: 3.6749\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3393,\tval_loss: 3.9238\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.3037,\tval_loss: 4.0260\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.3730,\tval_loss: 3.9050\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1315,\tval_loss: 4.0322\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1416,\tval_loss: 3.8522\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1553,\tval_loss: 3.8137\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1285,\tval_loss: 3.7686\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0512,\tval_loss: 3.7528\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.0774,\tval_loss: 3.9423\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2089,\tval_loss: 3.9649\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1912,\tval_loss: 3.9775\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.0775,\tval_loss: 3.9690\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0771,\tval_loss: 3.8774\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 4.0819,\tval_loss: 3.9117\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 3.9850,\tval_loss: 3.8519\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 3.9772,\tval_loss: 3.8487\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1765,\tval_loss: 3.9682\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.1157,\tval_loss: 3.7157\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.0559,\tval_loss: 3.8457\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.0794,\tval_loss: 3.7855\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.2598,\tval_loss: 3.8198\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.0839,\tval_loss: 3.7895\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1665,\tval_loss: 3.9100\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.0906,\tval_loss: 3.8095\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 4.0825,\tval_loss: 3.9162\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 4.1907,\tval_loss: 3.9952\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 4.1383,\tval_loss: 3.9526\n",
      "27:\t[0s / 4s],\t\ttrain_loss: 4.1776,\tval_loss: 3.9512\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5543,\tval_loss: 3.9065\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1668,\tval_loss: 3.8734\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.0563,\tval_loss: 3.7203\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1701,\tval_loss: 3.8297\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2270,\tval_loss: 3.8553\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1937,\tval_loss: 3.8381\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1400,\tval_loss: 3.7952\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2055,\tval_loss: 3.8632\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1244,\tval_loss: 3.8020\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1235,\tval_loss: 3.8208\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2698,\tval_loss: 3.8813\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1583,\tval_loss: 3.8948\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1830,\tval_loss: 3.8857\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.7138,\tval_loss: 3.9153\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1335,\tval_loss: 3.9371\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1683,\tval_loss: 3.9944\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.0898,\tval_loss: 3.7981\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1907,\tval_loss: 3.9800\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1912,\tval_loss: 3.7435\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2669,\tval_loss: 3.9590\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.2138,\tval_loss: 3.8950\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1707,\tval_loss: 3.8804\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1975,\tval_loss: 3.7709\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1664,\tval_loss: 3.9022\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1719,\tval_loss: 3.9008\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1283,\tval_loss: 3.8667\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1647,\tval_loss: 3.9234\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1438,\tval_loss: 3.9959\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.2065,\tval_loss: 4.0411\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5245,\tval_loss: 3.8086\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1148,\tval_loss: 3.7443\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.2110,\tval_loss: 3.6851\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.2042,\tval_loss: 3.7052\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1985,\tval_loss: 3.7702\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1775,\tval_loss: 3.6625\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.1576,\tval_loss: 3.7300\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1279,\tval_loss: 3.6950\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1031,\tval_loss: 3.6531\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1380,\tval_loss: 3.7896\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1765,\tval_loss: 3.8098\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1718,\tval_loss: 3.7998\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1712,\tval_loss: 3.7380\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.1069,\tval_loss: 3.6288\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.4583,\tval_loss: 3.6650\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 4.1469,\tval_loss: 3.8443\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 4.1058,\tval_loss: 3.7919\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 4.2245,\tval_loss: 3.6849\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 4.1046,\tval_loss: 3.7651\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 4.1686,\tval_loss: 3.7252\n",
      "20:\t[0s / 3s],\t\ttrain_loss: 4.1816,\tval_loss: 3.7674\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 4.1905,\tval_loss: 3.7593\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 4.1569,\tval_loss: 3.6453\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 4.2193,\tval_loss: 3.6835\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4240,\tval_loss: 3.7602\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1983,\tval_loss: 3.6607\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1506,\tval_loss: 3.7207\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1921,\tval_loss: 3.7623\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1888,\tval_loss: 3.7929\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.2095,\tval_loss: 3.7516\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2591,\tval_loss: 3.7360\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1985,\tval_loss: 3.6910\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1241,\tval_loss: 3.7173\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1266,\tval_loss: 3.7022\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.2141,\tval_loss: 3.7273\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1794,\tval_loss: 3.6644\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6732,\tval_loss: 3.9184\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.0994,\tval_loss: 4.2687\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1779,\tval_loss: 3.6184\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1313,\tval_loss: 3.7374\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.2671,\tval_loss: 3.5975\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1562,\tval_loss: 3.7518\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 4.2099,\tval_loss: 3.6921\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.0269,\tval_loss: 3.6308\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.1977,\tval_loss: 3.6761\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.1833,\tval_loss: 3.8510\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1400,\tval_loss: 3.8503\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.1551,\tval_loss: 3.8251\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.0466,\tval_loss: 3.7441\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 4.2246,\tval_loss: 3.6487\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 4.1747,\tval_loss: 3.6577\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.4620,\tval_loss: 4.0566\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1701,\tval_loss: 4.3383\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1749,\tval_loss: 4.0670\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.1845,\tval_loss: 3.9024\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.1687,\tval_loss: 4.0613\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.1881,\tval_loss: 4.2493\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.2275,\tval_loss: 3.9976\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 4.1028,\tval_loss: 4.0418\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 4.2435,\tval_loss: 3.9980\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 4.2196,\tval_loss: 4.1177\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 4.1862,\tval_loss: 4.0111\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 4.2584,\tval_loss: 4.0013\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 4.1295,\tval_loss: 4.1096\n",
      "13:\t[0s / 1s],\t\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 4.6339,\tval_loss: 3.4685\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.1504,\tval_loss: 3.0479\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.1452,\tval_loss: 3.5803\n",
      "3:\t[0s / 0s],\t\n",
      "4:\t[0s / 0s],\t\n",
      "5:\t[0s / 0s],\t\n",
      "6:\t[0s / 0s],\t\n",
      "7:\t[0s / 1s],\t\n",
      "8:\t[0s / 1s],\t\n",
      "9:\t[0s / 1s],\t\n",
      "10:\t[0s / 1s],\t\n",
      "11:\t[0s / 1s],\t\n",
      "Iteration 10, Average C-index: 0.7176483645700847, Average IBS: 0.09189493625328347\n",
      "Overall Average C-index: 0.7087607688800365, Standard Deviation of C-index: 0.00953805212223421\n",
      "Overall Average IBS: 0.09188431899839336, Standard Deviation of IBS: 0.0008283300750720402\n"
     ]
    }
   ],
   "source": [
    "# best_params should contain keys like 'num_layers', 'units', 'dropout', etc.\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import torchtuples as tt\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "c_indices_all = []\n",
    "ibs_scores_all = []\n",
    "\n",
    "for iteration in range(10):\n",
    "    random_state = 2775 + iteration\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    c_indices = []\n",
    "    ibs_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(x_train)):\n",
    "        x_train_fold = x_train[train_idx]\n",
    "        y_train_fold = y_train[0][train_idx], y_train[1][train_idx]\n",
    "        x_val_fold = x_train[val_idx]\n",
    "        y_val_fold = y_train[0][val_idx], y_train[1][val_idx]\n",
    "\n",
    "        # Using best parameters for MLPVanilla architecture\n",
    "        in_features = x_train.shape[1]\n",
    "        out_features = 1  # assuming CoxPH model\n",
    "        num_nodes = [best_params['units']] * best_params['num_layers']\n",
    "        batch_norm = False  # set as needed\n",
    "        dropout = best_params['dropout']\n",
    "        output_bias = False  # set as needed\n",
    "\n",
    "        net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout=dropout, output_bias=output_bias)\n",
    "        model = CoxPH(net, tt.optim.Adam(lr=best_params['lr']))\n",
    "\n",
    "        # Train the model\n",
    "        batch_size =91 #best_params['batch_size']\n",
    "        epochs = 250  # Adjust as necessary\n",
    "        callbacks = [tt.callbacks.EarlyStopping()]\n",
    "        verbose = True\n",
    "\n",
    "        log = model.fit(x_train_fold, y_train_fold, batch_size, epochs, callbacks, verbose,\n",
    "                        val_data=(x_val_fold, y_val_fold), val_batch_size=batch_size)\n",
    "#         log.plot()\n",
    "        # Evaluate the model\n",
    "        _ = model.compute_baseline_hazards()\n",
    "        surv = model.predict_surv_df(x_test)\n",
    "        # surv = model.predict_surv_df(x_val_fold)\n",
    "        # ev = EvalSurv(surv, y_val_fold[0], y_val_fold[1], censor_surv='km')\n",
    "        ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
    "\n",
    "        # Compute C-index and IBS\n",
    "        c_index = ev.concordance_td()\n",
    "        c_indices.append(c_index)\n",
    "#         time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "        time_grid = np.linspace(y_val_fold[0].min(), y_val_fold[0].max(), 100)\n",
    "        ibs = ev.integrated_brier_score(time_grid)\n",
    "        ibs_scores.append(ibs)\n",
    "\n",
    "    c_indices_all.append(np.mean(c_indices))\n",
    "    ibs_scores_all.append(np.mean(ibs_scores))\n",
    "\n",
    "    print(f'Iteration {iteration+1}, Average C-index: {np.mean(c_indices)}, Average IBS: {np.mean(ibs_scores)}')\n",
    "\n",
    "# Calculate the overall average and standard deviation outside the iterations loop\n",
    "final_avg_c_index = np.mean(c_indices_all)\n",
    "std_dev_c_index = np.std(c_indices_all)\n",
    "\n",
    "final_avg_ibs = np.mean(ibs_scores_all)\n",
    "std_dev_ibs = np.std(ibs_scores_all)\n",
    "\n",
    "print(f'Overall Average C-index: {final_avg_c_index}, Standard Deviation of C-index: {std_dev_c_index}')\n",
    "print(f'Overall Average IBS: {final_avg_ibs}, Standard Deviation of IBS: {std_dev_ibs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c732cdfc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (0.41.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (1.1.2)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (1.2.4)\n",
      "Requirement already satisfied: numba in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (0.53.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (1.6.2)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from shap) (4.59.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from packaging>20.9->shap) (2.4.7)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from numba->shap) (0.36.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from numba->shap) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pandas->shap) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gyedu\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "facb8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your numpy arrays to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3696790",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = x_train_tensor  # You can choose a different subset\n",
    "\n",
    "# Initialize SHAP DeepExplainer\n",
    "explainer = shap.DeepExplainer(model.net, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb99db81",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    }
   ],
   "source": [
    "# Compute SHAP values for a subset of your test set\n",
    "shap_values = explainer.shap_values(x_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d21e8e70",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x626.4 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Visualization\n",
    "shap.summary_plot(shap_values, features=x_test_tensor.numpy(), feature_names=x_mapper.transformed_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3d70c7d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x626.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "import torch\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values, features=x_test, feature_names=x_mapper.transformed_names_, plot_type='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
